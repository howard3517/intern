{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd4d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad2548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b5b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    locals()['df'+str(i)] = pd.read_csv(str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a922ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#將所有格子分成五個不同的測試集\n",
    "def split():\n",
    "    for i in range(1,6):\n",
    "        locals()['df'+str(i)] = pd.read_csv(str(i)+'.csv')\n",
    "    \n",
    "    da = df1.index\n",
    "    for i in range(5,1,-1):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(da,da,test_size=1/i,random_state=0)\n",
    "        if i == 5:\n",
    "            test1 = X_test.tolist()\n",
    "            test1.sort()\n",
    "        if i == 4:\n",
    "            test2 = X_test.tolist()\n",
    "            test2.sort()\n",
    "        if i == 3:\n",
    "            test3 = X_test.tolist()\n",
    "            test3.sort()\n",
    "        if i == 2:\n",
    "            test4 = X_test.tolist()\n",
    "            test4.sort()\n",
    "            test5 = X_train.tolist()\n",
    "            test5.sort()\n",
    "        da = X_train \n",
    "        \n",
    "        \n",
    "    return test1,test2,test3,test4,test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c049ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(ls):\n",
    "    # split data\n",
    "    df = pd.read_csv('1.csv')\n",
    "    df = df.drop(index=ls,axis=1)\n",
    "    X_train,X_va,y_train,y_va = train_test_split(df.index,df.index,test_size=0.2,random_state=0)\n",
    "    train = X_train.tolist()\n",
    "    train.sort() #train index list\n",
    "    \n",
    "    validation = X_va.tolist()\n",
    "    validation.sort() #validation index list\n",
    "\n",
    "    \n",
    "    # make training data\n",
    "    for i in range(1,5):\n",
    "        locals()['df'+str(i)] = pd.read_csv(str(i)+'.csv')\n",
    "        locals()['df'+str(i)] = locals()['df'+str(i)].loc[train,:]        \n",
    "    traindf = pd.concat([locals()['df'+str(1)],locals()['df'+str(2)],locals()['df'+str(3)],locals()['df'+str(4)]],axis=0)\n",
    "    \n",
    "    \n",
    "    #make validation data\n",
    "    for i in range(1,5):\n",
    "        locals()['df'+str(i)] = pd.read_csv(str(i)+'.csv')\n",
    "        locals()['df'+str(i)] = locals()['df'+str(i)].loc[validation,:]\n",
    "    vadf = pd.concat([locals()['df'+str(1)],locals()['df'+str(2)],locals()['df'+str(3)],locals()['df'+str(4)]],axis=0)\n",
    "    \n",
    "    \n",
    "    #make testing data\n",
    "    df5 = pd.read_csv('5.csv')\n",
    "    testdf = df5.loc[ls,:]\n",
    "    \n",
    "    return traindf,vadf,testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ecb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2,t3,t4,t5 = split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dab9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    locals()['train'+str(i)],locals()['va'+str(i)],locals()['test'+str(i)] = make(locals()['t'+str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618bffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1,va1,test1 = make(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474273b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(Dataset):\n",
    "    def __init__(self,df): # get data and label\n",
    "        self.x = df.drop(['bank','college'],axis=1).values\n",
    "        self.y = df['bank'].values\n",
    "        \n",
    "    def __getitem__(self,index): # get index\n",
    "        \n",
    "        return self.x[index],self.y[index]\n",
    "        \n",
    "    def __len__(self): # get length\n",
    "        \n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f37e97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/300] loss: 4.7893323       9.3173965\n",
      "[2/300] loss: 4.0962412       7.1405286\n",
      "[3/300] loss: 3.3258145       6.0666922\n",
      "[4/300] loss: 2.7263314       5.03038\n",
      "[5/300] loss: 2.3264445       4.4290941\n",
      "[6/300] loss: 2.060235       4.0030307\n",
      "[7/300] loss: 2.0545049       3.7418254\n",
      "[8/300] loss: 1.8809334       3.7168601\n",
      "[9/300] loss: 1.8134099       3.8035957\n",
      "[10/300] loss: 1.7875224       3.3715631\n",
      "[11/300] loss: 1.7411293       3.351657\n",
      "[12/300] loss: 1.7115687       3.5559184\n",
      "[13/300] loss: 1.6868716       3.2118302\n",
      "[14/300] loss: 1.6054712       3.2269993\n",
      "[15/300] loss: 1.6061873       3.1348361\n",
      "[16/300] loss: 1.5657464       3.5551848\n",
      "[17/300] loss: 1.5533489       3.1353001\n",
      "[18/300] loss: 1.5680978       3.0946318\n",
      "[19/300] loss: 1.5224957       2.8742121\n",
      "[20/300] loss: 1.5258409       2.8116968\n",
      "[21/300] loss: 1.550076       2.9575394\n",
      "[22/300] loss: 1.4450264       2.7457151\n",
      "[23/300] loss: 1.47963       3.0821713\n",
      "[24/300] loss: 1.5898745       3.3632964\n",
      "[25/300] loss: 1.4629579       2.7686498\n",
      "[26/300] loss: 1.5094205       2.6851283\n",
      "[27/300] loss: 1.4270901       2.7034328\n",
      "[28/300] loss: 1.364172       2.706369\n",
      "[29/300] loss: 1.4938307       2.5496605\n",
      "[30/300] loss: 1.3667023       2.5378648\n",
      "[31/300] loss: 1.393008       2.9142669\n",
      "[32/300] loss: 1.4438065       2.7307223\n",
      "[33/300] loss: 1.482275       3.4922923\n",
      "[34/300] loss: 1.2946731       2.5543155\n",
      "[35/300] loss: 1.31628       2.5277978\n",
      "[36/300] loss: 1.2890245       2.5048966\n",
      "[37/300] loss: 1.3542612       2.5946645\n",
      "[38/300] loss: 1.3730893       2.6287789\n",
      "[39/300] loss: 1.2403354       2.2627273\n",
      "[40/300] loss: 1.2008186       2.7427981\n",
      "[41/300] loss: 1.219684       2.4453554\n",
      "[42/300] loss: 1.2086297       3.2336852\n",
      "[43/300] loss: 1.510605       2.4125956\n",
      "[44/300] loss: 1.1339924       2.4746637\n",
      "[45/300] loss: 1.1475082       2.3936673\n",
      "[46/300] loss: 1.2473608       2.5384631\n",
      "[47/300] loss: 1.1969793       2.3668864\n",
      "[48/300] loss: 1.1835315       2.6530209\n",
      "[49/300] loss: 1.1074644       2.2980483\n",
      "[50/300] loss: 1.0546371       2.2576011\n",
      "[51/300] loss: 1.0705551       2.2953061\n",
      "[52/300] loss: 1.1099501       2.1544371\n",
      "[53/300] loss: 1.3085238       2.3140903\n",
      "[54/300] loss: 1.053546       2.2275154\n",
      "[55/300] loss: 1.1030832       2.5011572\n",
      "[56/300] loss: 1.008867       2.3699829\n",
      "[57/300] loss: 1.0010831       2.3553814\n",
      "[58/300] loss: 1.0454236       2.2219878\n",
      "[59/300] loss: 1.025979       2.2174871\n",
      "[60/300] loss: 1.18412       2.1669714\n",
      "[61/300] loss: 0.97241309       2.403677\n",
      "[62/300] loss: 1.0925517       2.116665\n",
      "[63/300] loss: 1.1084094       2.3328017\n",
      "[64/300] loss: 1.04763       2.0971337\n",
      "[65/300] loss: 1.1126541       2.2305667\n",
      "[66/300] loss: 0.99465836       2.2940639\n",
      "[67/300] loss: 1.0922373       2.5119369\n",
      "[68/300] loss: 1.0365419       2.2263588\n",
      "[69/300] loss: 1.0710098       2.4598454\n",
      "[70/300] loss: 1.0586224       2.6626674\n",
      "[71/300] loss: 1.0463527       2.1732713\n",
      "[72/300] loss: 0.92290288       2.3812968\n",
      "[73/300] loss: 0.94766994       2.173826\n",
      "[74/300] loss: 1.0166553       2.525079\n",
      "[75/300] loss: 1.0182914       2.2169974\n",
      "[76/300] loss: 1.0771427       2.2258559\n",
      "[77/300] loss: 1.1367995       2.2020632\n",
      "[78/300] loss: 0.94475191       2.3268928\n",
      "[79/300] loss: 0.93581915       2.2020089\n",
      "[80/300] loss: 0.89357038       2.1135048\n",
      "[81/300] loss: 0.97282797       2.2274327\n",
      "[82/300] loss: 0.95035212       2.2653554\n",
      "[83/300] loss: 0.90996251       2.1997243\n",
      "[84/300] loss: 0.87394835       2.292833\n",
      "[85/300] loss: 0.85972       2.5629076\n",
      "[86/300] loss: 0.84508129       2.259616\n",
      "[87/300] loss: 0.87902286       3.3905518\n",
      "[88/300] loss: 1.1076379       2.5296401\n",
      "[89/300] loss: 0.96665961       2.5161447\n",
      "[90/300] loss: 0.90875531       3.1299844\n",
      "[91/300] loss: 0.9464692       2.1841694\n",
      "[92/300] loss: 0.87065173       2.2755078\n",
      "[93/300] loss: 0.80367996       2.345676\n",
      "[94/300] loss: 0.86384498       2.1881966\n",
      "[95/300] loss: 0.84153115       2.6194404\n",
      "[96/300] loss: 0.79775636       2.2941547\n",
      "[97/300] loss: 0.85227593       2.3882675\n",
      "[98/300] loss: 0.82442218       2.3940633\n",
      "[99/300] loss: 0.81829653       2.2320775\n",
      "[100/300] loss: 0.80806414       2.0727873\n",
      "[101/300] loss: 0.80858659       2.3864976\n",
      "[102/300] loss: 0.84080333       2.4438926\n",
      "[103/300] loss: 0.84065424       2.1662201\n",
      "[104/300] loss: 0.90666053       2.1410738\n",
      "[105/300] loss: 0.92790075       2.1796785\n",
      "[106/300] loss: 0.85203281       2.0906605\n",
      "[107/300] loss: 0.80061181       2.3352985\n",
      "[108/300] loss: 0.7883923       2.1694573\n",
      "[109/300] loss: 0.8088481       2.7317925\n",
      "[110/300] loss: 0.79846716       2.6185975\n",
      "[111/300] loss: 0.91123019       2.6913082\n",
      "[112/300] loss: 0.82283395       2.3331734\n",
      "[113/300] loss: 0.84116452       2.1609231\n",
      "[114/300] loss: 0.82585733       2.259848\n",
      "[115/300] loss: 0.80275722       2.4726648\n",
      "[116/300] loss: 0.73186851       2.3105771\n",
      "[117/300] loss: 0.9261638       2.3018039\n",
      "[118/300] loss: 0.78806064       2.32003\n",
      "[119/300] loss: 0.81009471       2.0876947\n",
      "[120/300] loss: 0.88846064       2.4082581\n",
      "[121/300] loss: 0.79226285       2.2096979\n",
      "[122/300] loss: 0.80650282       2.6946121\n",
      "[123/300] loss: 0.95837331       2.0381859\n",
      "[124/300] loss: 0.97213006       2.2165177\n",
      "[125/300] loss: 0.87506347       2.3663342\n",
      "[126/300] loss: 0.71888013       2.124348\n",
      "[127/300] loss: 0.72345464       2.3423879\n",
      "[128/300] loss: 0.7691101       2.0640679\n",
      "[129/300] loss: 0.72222285       2.2883242\n",
      "[130/300] loss: 0.82654657       2.2664951\n",
      "[131/300] loss: 0.71264131       2.2195706\n",
      "[132/300] loss: 0.76016976       2.2543496\n",
      "[133/300] loss: 0.78226814       2.3420455\n",
      "[134/300] loss: 0.74757593       2.2024288\n",
      "[135/300] loss: 0.69006978       2.3149458\n",
      "[136/300] loss: 0.78357053       2.5371978\n",
      "[137/300] loss: 0.82598338       2.0051664\n",
      "[138/300] loss: 0.74605108       2.2581576\n",
      "[139/300] loss: 0.76789011       2.0982966\n",
      "[140/300] loss: 0.74803914       2.3353714\n",
      "[141/300] loss: 0.87793767       2.5074508\n",
      "[142/300] loss: 0.70259611       2.0662552\n",
      "[143/300] loss: 0.72045975       2.8082853\n",
      "[144/300] loss: 0.66767634       2.112799\n",
      "[145/300] loss: 0.7113506       2.4888207\n",
      "[146/300] loss: 0.74671574       2.1154172\n",
      "[147/300] loss: 0.7057255       2.0672562\n",
      "[148/300] loss: 0.71866122       2.2089398\n",
      "[149/300] loss: 0.85085032       2.1100856\n",
      "[150/300] loss: 0.70170121       2.1728148\n",
      "[151/300] loss: 0.69118181       2.4836164\n",
      "[152/300] loss: 0.74894109       2.2027396\n",
      "[153/300] loss: 0.70319066       2.1546812\n",
      "[154/300] loss: 0.68925259       2.2881648\n",
      "[155/300] loss: 0.64667792       2.1677878\n",
      "[156/300] loss: 0.67484035       2.0884951\n",
      "[157/300] loss: 0.68042533       2.4322229\n",
      "[158/300] loss: 0.73884368       2.4671738\n",
      "[159/300] loss: 0.66762878       2.3027994\n",
      "[160/300] loss: 0.6495708       2.5540031\n",
      "[161/300] loss: 0.65090058       2.3928647\n",
      "[162/300] loss: 0.65250715       2.171494\n",
      "[163/300] loss: 0.64386967       2.0852701\n",
      "[164/300] loss: 0.72182791       2.1129869\n",
      "[165/300] loss: 0.69978802       2.1527329\n",
      "[166/300] loss: 0.64720664       2.2084501\n",
      "[167/300] loss: 0.61985207       2.5811785\n",
      "[168/300] loss: 0.78727344       2.7758413\n",
      "[169/300] loss: 0.65092471       2.5141831\n",
      "[170/300] loss: 0.67334822       2.0383093\n",
      "[171/300] loss: 0.63795209       2.2971656\n",
      "[172/300] loss: 0.62360287       2.5024467\n",
      "[173/300] loss: 0.62233686       2.6120499\n",
      "[174/300] loss: 0.69785815       2.2241067\n",
      "[175/300] loss: 0.59400758       2.623727\n",
      "[176/300] loss: 0.62819954       2.0234728\n",
      "[177/300] loss: 0.64411646       2.3370219\n",
      "[178/300] loss: 0.67865028       2.3113774\n",
      "[179/300] loss: 0.69541426       2.0678173\n",
      "[180/300] loss: 0.63166432       2.0698606\n",
      "[181/300] loss: 0.60514985       2.2220518\n",
      "[182/300] loss: 0.6470677       2.3033903\n",
      "[183/300] loss: 0.63054054       2.4101587\n",
      "[184/300] loss: 0.78738778       2.5897747\n",
      "[185/300] loss: 0.8668542       2.5488196\n",
      "[186/300] loss: 0.81212879       2.159837\n",
      "[187/300] loss: 0.63415739       2.1465331\n",
      "[188/300] loss: 0.65596448       2.5988292\n",
      "[189/300] loss: 0.5797696       2.7139877\n",
      "[190/300] loss: 0.59623317       2.1962455\n",
      "[191/300] loss: 0.63436501       2.2451403\n",
      "[192/300] loss: 0.58799986       2.4357511\n",
      "[193/300] loss: 0.61228796       2.2097008\n",
      "[194/300] loss: 0.60062608       2.2339181\n",
      "[195/300] loss: 0.63008221       2.206374\n",
      "[196/300] loss: 0.59568959       2.1470957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197/300] loss: 0.60659094       2.0229152\n",
      "[198/300] loss: 0.62778556       2.2014319\n",
      "[199/300] loss: 0.57235858       2.4356185\n",
      "[200/300] loss: 0.59719113       2.0656155\n",
      "[201/300] loss: 0.60539888       2.170992\n",
      "[202/300] loss: 0.55287476       2.0133686\n",
      "[203/300] loss: 0.62486766       2.6540652\n",
      "[204/300] loss: 0.61493351       2.2730177\n",
      "[205/300] loss: 0.565641       2.4359297\n",
      "[206/300] loss: 0.6743592       2.1211252\n",
      "[207/300] loss: 0.55023731       2.15614\n",
      "[208/300] loss: 0.78432236       2.3404001\n",
      "[209/300] loss: 0.60715901       2.2070365\n",
      "[210/300] loss: 0.54526974       2.3166381\n",
      "[211/300] loss: 0.65177279       2.1952941\n",
      "[212/300] loss: 0.558951       2.4714622\n",
      "[213/300] loss: 0.60920385       2.3299017\n",
      "[214/300] loss: 0.55461041       2.306899\n",
      "[215/300] loss: 0.55280646       2.3551354\n",
      "[216/300] loss: 0.59172107       2.501604\n",
      "[217/300] loss: 0.51320726       2.3406857\n",
      "[218/300] loss: 0.52885655       2.1344745\n",
      "[219/300] loss: 0.55943521       2.424197\n",
      "[220/300] loss: 0.54109023       2.4526524\n",
      "[221/300] loss: 0.5445321       2.4306875\n",
      "[222/300] loss: 0.5383765       2.2596862\n",
      "[223/300] loss: 0.52455861       2.2620477\n",
      "[224/300] loss: 0.5501713       2.3622729\n",
      "[225/300] loss: 0.56872471       2.0874151\n",
      "[226/300] loss: 0.54108684       2.1246767\n",
      "[227/300] loss: 0.57201741       2.7896329\n",
      "[228/300] loss: 0.59944939       2.400271\n",
      "[229/300] loss: 0.6685094       2.2299745\n",
      "[230/300] loss: 0.57832448       2.5354862\n",
      "[231/300] loss: 0.49111808       2.561148\n",
      "[232/300] loss: 0.60003671       2.1803355\n",
      "[233/300] loss: 0.65536716       2.1264737\n",
      "[234/300] loss: 0.55524968       2.1245179\n",
      "[235/300] loss: 0.51722016       2.0755058\n",
      "[236/300] loss: 0.54229842       3.0223058\n",
      "[237/300] loss: 0.50012114       2.1559065\n",
      "[238/300] loss: 0.47137116       2.4652086\n",
      "[239/300] loss: 0.4649787       2.6259062\n",
      "[240/300] loss: 0.54101145       2.6180587\n",
      "[241/300] loss: 0.52733229       2.8944483\n",
      "[242/300] loss: 0.52749631       2.2930865\n",
      "[243/300] loss: 0.49296616       2.7678471\n",
      "[244/300] loss: 0.54079456       2.5164258\n",
      "[245/300] loss: 0.53150013       2.4820425\n",
      "[246/300] loss: 0.53521845       2.220981\n",
      "[247/300] loss: 0.51160594       2.3275921\n",
      "[248/300] loss: 0.53959491       2.1678574\n",
      "[249/300] loss: 0.49240241       2.1710473\n",
      "[250/300] loss: 0.51077226       2.8238497\n",
      "[251/300] loss: 0.48967841       2.2168692\n",
      "[252/300] loss: 0.52310473       3.1055778\n",
      "[253/300] loss: 0.46669441       2.198\n",
      "[254/300] loss: 0.45963638       2.1695841\n",
      "[255/300] loss: 0.47169075       2.2369638\n",
      "[256/300] loss: 0.55152028       2.7156727\n",
      "[257/300] loss: 0.47053671       2.2796284\n",
      "[258/300] loss: 0.50007144       2.6376324\n",
      "[259/300] loss: 0.44133241       2.5431488\n",
      "[260/300] loss: 0.49708174       2.3865765\n",
      "[261/300] loss: 0.7117736       2.2041189\n",
      "[262/300] loss: 0.46573212       2.1246336\n",
      "[263/300] loss: 0.49396195       2.2038283\n",
      "[264/300] loss: 0.54968729       2.3433297\n",
      "[265/300] loss: 0.49554468       2.7364309\n",
      "[266/300] loss: 0.48211107       2.1101101\n",
      "[267/300] loss: 0.42472438       2.5663349\n",
      "[268/300] loss: 0.4423183       2.3133503\n",
      "[269/300] loss: 0.45525708       2.2236396\n",
      "[270/300] loss: 0.44555739       2.528986\n",
      "[271/300] loss: 0.5587654       2.7435247\n",
      "[272/300] loss: 0.50376147       2.071306\n",
      "[273/300] loss: 0.44453875       2.2449938\n",
      "[274/300] loss: 0.57452032       2.3078066\n",
      "[275/300] loss: 0.48189655       2.3787835\n",
      "[276/300] loss: 0.43861505       2.3326993\n",
      "[277/300] loss: 0.45534036       2.2921992\n",
      "[278/300] loss: 0.47422877       2.2419526\n",
      "[279/300] loss: 0.40355329       2.0505766\n",
      "[280/300] loss: 0.41592487       2.3418516\n",
      "[281/300] loss: 0.44608007       2.5464227\n",
      "[282/300] loss: 0.42681249       2.8094925\n",
      "[283/300] loss: 0.61320485       2.7005115\n",
      "[284/300] loss: 0.54811446       2.0346543\n",
      "[285/300] loss: 0.43540834       2.2772552\n",
      "[286/300] loss: 0.49508862       2.2403626\n",
      "[287/300] loss: 0.4269206       2.2298923\n",
      "[288/300] loss: 0.41572442       2.4032041\n",
      "[289/300] loss: 0.4857066       2.2097771\n",
      "[290/300] loss: 0.40358736       2.4824171\n",
      "[291/300] loss: 0.53341669       2.6684544\n",
      "[292/300] loss: 0.42090453       2.308799\n",
      "[293/300] loss: 0.41864686       2.2552209\n",
      "[294/300] loss: 0.42883296       2.5739618\n",
      "[295/300] loss: 0.4102178       2.5333455\n",
      "[296/300] loss: 0.49012991       2.2773889\n",
      "[297/300] loss: 0.42467354       2.1129099\n",
      "[298/300] loss: 0.37885433       2.2798491\n",
      "[299/300] loss: 0.38244183       2.2442618\n",
      "[300/300] loss: 0.39158463       2.1309009\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class dnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dnn,self).__init__()\n",
    "        self.hid1 = nn.Linear(17, 16)  \n",
    "        self.hid2 = nn.Linear(16, 16)\n",
    "        self.hid3 = nn.Linear(16, 8)\n",
    "        self.hid4 = nn.Linear(8, 8)\n",
    "        self.hid5 = nn.Linear(8, 4)\n",
    "        self.oupt = nn.Linear(4, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = F.relu(self.hid1(x))\n",
    "        z = F.relu(self.hid2(z))\n",
    "        z = F.relu(self.hid3(z))\n",
    "        z = F.relu(self.hid4(z))\n",
    "        z = F.relu(self.hid5(z))\n",
    "        z = self.oupt(z)  \n",
    "        return z\n",
    "    \n",
    "def train( model, epochs, optimizer, loss_function, train_loader, valid_loader):\n",
    "    tl = []\n",
    "    vl = []\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 2\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        #print(model.training)\n",
    "        los = 0\n",
    "        for times, (f,l) in enumerate(train_loader):\n",
    "            \n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward propagation\n",
    "            outputs = model(f)\n",
    "            l = l.unsqueeze(1)\n",
    "            loss = loss_function(outputs, l)\n",
    "            los += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            for i,(data, target) in enumerate(valid_loader):\n",
    "                \n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(data)\n",
    "                target = target.unsqueeze(1)\n",
    "                # calculate the batch loss\n",
    "                lo = loss_function(output, target)\n",
    "                # update average validation loss \n",
    "                valid_loss += lo\n",
    "  \n",
    "\n",
    "            \n",
    "            \n",
    "            # Show progress\n",
    "            #if times % 100 == 0 or times == len(train_loader):\n",
    "                \n",
    "        print('[{}/{}] loss: {:.8}       {:.8}'.format(epoch, epochs, float(los/times),float(valid_loss/i)))\n",
    "        tl.append(float(los/times))\n",
    "        vl.append(float(valid_loss/i))\n",
    "    return tl,vl,model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    name = df1.columns.tolist()\n",
    "    for n in name:\n",
    "        train1[n] = train1[n].astype(float)\n",
    "        va1[n] = va1[n].astype(float)\n",
    "\n",
    "    data = mydata(train1)\n",
    "    train_loader = DataLoader(dataset=data,batch_size=64,shuffle=True)\n",
    "\n",
    "    data = mydata(va1)\n",
    "    valid_loader = DataLoader(dataset=data,batch_size=64,shuffle=True)\n",
    "\n",
    "    dnn = dnn()\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(dnn.parameters(), lr=1e-3)\n",
    "\n",
    "    tl,vl,model = train( dnn, 300, optimizer, loss_function, train_loader, valid_loader)\n",
    "    plt.plot(tl,label='train')\n",
    "    plt.plot(vl,label='validation')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a40ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dnn,self).__init__()\n",
    "        self.hid1 = nn.Linear(17, 16)  \n",
    "        self.hid2 = nn.Linear(16, 16)\n",
    "        self.hid3 = nn.Linear(16, 8)\n",
    "        self.hid4 = nn.Linear(8, 8)\n",
    "        self.hid5 = nn.Linear(8, 8)\n",
    "        self.hid6 = nn.Linear(8, 8)\n",
    "        self.hid7 = nn.Linear(8, 8)\n",
    "        self.hid8 = nn.Linear(8, 8)\n",
    "        self.hid11 = nn.Linear(8, 8)\n",
    "        self.hid12 = nn.Linear(8, 4)\n",
    "        self.oupt = nn.Linear(4, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = F.relu(self.hid1(x))\n",
    "        z = F.relu(self.hid2(z))\n",
    "        z = F.relu(self.hid3(z))\n",
    "        z = F.relu(self.hid4(z))\n",
    "        z = F.relu(self.hid5(z))\n",
    "        z = F.relu(self.hid6(z))\n",
    "        z = F.relu(self.hid7(z))\n",
    "        z = F.relu(self.hid8(z))\n",
    "        z = F.relu(self.hid11(z))\n",
    "        z = F.relu(self.hid12(z))\n",
    "        z = self.oupt(z)  \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c67b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, epochs, optimizer, loss_function, train_loader, valid_loader):\n",
    "    tl = []\n",
    "    vl = []\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 2\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        \n",
    "        #print(model.training)\n",
    "        los = 0\n",
    "        for times, (f,l) in enumerate(train_loader):\n",
    "            \n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward propagation\n",
    "            outputs = model(f)\n",
    "            l = l.unsqueeze(1)\n",
    "            loss = loss_function(outputs, l)\n",
    "            los += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            for i,(data, target) in enumerate(valid_loader):\n",
    "                \n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(data)\n",
    "                target = target.unsqueeze(1)\n",
    "                # calculate the batch loss\n",
    "                lo = loss_function(output, target)\n",
    "                # update average validation loss \n",
    "                valid_loss += lo\n",
    "  \n",
    "\n",
    "            \n",
    "            \n",
    "            # Show progress\n",
    "            #if times % 100 == 0 or times == len(train_loader):\n",
    "                \n",
    "        print('[{}/{}] loss: {:.8}       {:.8}'.format(epoch, epochs, float(los/times),float(valid_loss/i)))\n",
    "        tl.append(float(los/times))\n",
    "        vl.append(float(valid_loss/i))\n",
    "    return tl,vl,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8c0dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] loss: 971.82458       964.8571\n",
      "[2/1000] loss: 926.54753       893.90304\n",
      "[3/1000] loss: 883.98267       852.21566\n",
      "[4/1000] loss: 843.87361       830.29914\n",
      "[5/1000] loss: 803.57265       766.61505\n",
      "[6/1000] loss: 768.04964       745.62244\n",
      "[7/1000] loss: 733.41667       703.66739\n",
      "[8/1000] loss: 696.5217       694.57944\n",
      "[9/1000] loss: 664.36235       659.7464\n",
      "[10/1000] loss: 633.67733       604.32963\n",
      "[11/1000] loss: 601.74246       592.24944\n",
      "[12/1000] loss: 572.37536       547.73101\n",
      "[13/1000] loss: 543.45196       521.57901\n",
      "[14/1000] loss: 516.0671       525.87901\n",
      "[15/1000] loss: 489.17592       484.2266\n",
      "[16/1000] loss: 462.71712       475.61567\n",
      "[17/1000] loss: 435.85886       422.65702\n",
      "[18/1000] loss: 410.65174       405.51724\n",
      "[19/1000] loss: 385.66583       384.36806\n",
      "[20/1000] loss: 360.2811       356.68682\n",
      "[21/1000] loss: 336.11154       348.73676\n",
      "[22/1000] loss: 312.79063       313.5574\n",
      "[23/1000] loss: 290.81858       287.48395\n",
      "[24/1000] loss: 270.43036       274.16266\n",
      "[25/1000] loss: 250.38127       246.69956\n",
      "[26/1000] loss: 231.01362       241.05417\n",
      "[27/1000] loss: 213.52091       200.64907\n",
      "[28/1000] loss: 197.13876       186.06869\n",
      "[29/1000] loss: 181.2212       181.86754\n",
      "[30/1000] loss: 167.56821       159.83969\n",
      "[31/1000] loss: 153.59452       152.84812\n",
      "[32/1000] loss: 140.51326       133.33896\n",
      "[33/1000] loss: 128.58317       120.32796\n",
      "[34/1000] loss: 117.40805       115.99857\n",
      "[35/1000] loss: 107.27365       101.71673\n",
      "[36/1000] loss: 97.496188       92.059599\n",
      "[37/1000] loss: 88.789945       87.907617\n",
      "[38/1000] loss: 80.822553       74.681491\n",
      "[39/1000] loss: 72.904858       74.132253\n",
      "[40/1000] loss: 66.250446       63.436253\n",
      "[41/1000] loss: 59.669741       56.511663\n",
      "[42/1000] loss: 53.868477       50.78482\n",
      "[43/1000] loss: 48.572792       46.795379\n",
      "[44/1000] loss: 43.67305       42.27787\n",
      "[45/1000] loss: 39.273593       38.37257\n",
      "[46/1000] loss: 35.278493       34.981786\n",
      "[47/1000] loss: 31.687952       31.693013\n",
      "[48/1000] loss: 28.453071       28.239677\n",
      "[49/1000] loss: 25.598171       25.125903\n",
      "[50/1000] loss: 22.990119       23.831581\n",
      "[51/1000] loss: 20.788273       23.010976\n",
      "[52/1000] loss: 18.773009       19.288355\n",
      "[53/1000] loss: 17.076851       18.463017\n",
      "[54/1000] loss: 15.539792       18.048784\n",
      "[55/1000] loss: 14.184106       15.460749\n",
      "[56/1000] loss: 13.069738       15.692946\n",
      "[57/1000] loss: 12.060383       14.633162\n",
      "[58/1000] loss: 11.140147       13.628204\n",
      "[59/1000] loss: 10.355771       13.002043\n",
      "[60/1000] loss: 9.7294411       12.450198\n",
      "[61/1000] loss: 9.078406       12.159895\n",
      "[62/1000] loss: 8.5685762       11.837496\n",
      "[63/1000] loss: 8.1414742       10.80144\n",
      "[64/1000] loss: 7.7366494       12.321897\n",
      "[65/1000] loss: 7.3862819       10.185178\n",
      "[66/1000] loss: 7.0797466       11.721557\n",
      "[67/1000] loss: 6.8411358       11.109942\n",
      "[68/1000] loss: 6.5944462       9.7791721\n",
      "[69/1000] loss: 6.3780911       9.4433265\n",
      "[70/1000] loss: 6.191053       9.2851767\n",
      "[71/1000] loss: 6.0345163       9.3104698\n",
      "[72/1000] loss: 5.8833238       9.266858\n",
      "[73/1000] loss: 5.7381776       8.9908137\n",
      "[74/1000] loss: 5.6458561       9.674849\n",
      "[75/1000] loss: 5.4860556       8.666667\n",
      "[76/1000] loss: 5.3696857       8.8818471\n",
      "[77/1000] loss: 5.2737705       8.580031\n",
      "[78/1000] loss: 5.1967753       8.4634501\n",
      "[79/1000] loss: 5.0959948       8.3452691\n",
      "[80/1000] loss: 5.0100503       8.3469685\n",
      "[81/1000] loss: 4.9424919       9.3633535\n",
      "[82/1000] loss: 4.8609285       9.8979319\n",
      "[83/1000] loss: 4.7995642       9.2174149\n",
      "[84/1000] loss: 4.7058459       10.582829\n",
      "[85/1000] loss: 4.6749274       8.039486\n",
      "[86/1000] loss: 4.6011271       8.4265794\n",
      "[87/1000] loss: 4.5834011       7.909561\n",
      "[88/1000] loss: 4.5116456       8.0928435\n",
      "[89/1000] loss: 4.4697895       8.6367178\n",
      "[90/1000] loss: 4.4386454       7.9907556\n",
      "[91/1000] loss: 4.3943223       8.5752297\n",
      "[92/1000] loss: 4.4088672       7.8446082\n",
      "[93/1000] loss: 4.3392245       7.7692852\n",
      "[94/1000] loss: 4.3350381       10.583337\n",
      "[95/1000] loss: 4.2870859       8.3872665\n",
      "[96/1000] loss: 4.2729126       7.8746127\n",
      "[97/1000] loss: 4.2440989       7.7874566\n",
      "[98/1000] loss: 4.2365649       7.7205805\n",
      "[99/1000] loss: 4.244836       8.3375494\n",
      "[100/1000] loss: 4.1861873       7.7827278\n",
      "[101/1000] loss: 4.1762291       8.906233\n",
      "[102/1000] loss: 4.1899453       7.6339532\n",
      "[103/1000] loss: 4.1471827       8.7431115\n",
      "[104/1000] loss: 4.1315814       7.9828539\n",
      "[105/1000] loss: 4.1335617       7.8801292\n",
      "[106/1000] loss: 4.1002726       7.7270008\n",
      "[107/1000] loss: 4.0871175       7.6407452\n",
      "[108/1000] loss: 4.0708945       9.1591871\n",
      "[109/1000] loss: 4.0605882       7.584257\n",
      "[110/1000] loss: 4.0913618       7.9114838\n",
      "[111/1000] loss: 4.0341955       7.6069648\n",
      "[112/1000] loss: 4.0542289       8.0945692\n",
      "[113/1000] loss: 4.027024       7.6023874\n",
      "[114/1000] loss: 4.0196338       9.0730052\n",
      "[115/1000] loss: 4.0097665       7.5808035\n",
      "[116/1000] loss: 3.993555       9.0559013\n",
      "[117/1000] loss: 4.0143403       7.5190753\n",
      "[118/1000] loss: 3.9803162       7.8543286\n",
      "[119/1000] loss: 3.9596108       7.8468862\n",
      "[120/1000] loss: 3.9634269       7.7890174\n",
      "[121/1000] loss: 3.9597569       7.7687892\n",
      "[122/1000] loss: 3.9420067       7.7914777\n",
      "[123/1000] loss: 3.9328379       7.4714868\n",
      "[124/1000] loss: 3.9200003       7.7370716\n",
      "[125/1000] loss: 3.9550419       7.4571111\n",
      "[126/1000] loss: 3.9105798       7.7312679\n",
      "[127/1000] loss: 3.9324465       7.386621\n",
      "[128/1000] loss: 3.9309715       8.0251334\n",
      "[129/1000] loss: 3.9113129       7.4229546\n",
      "[130/1000] loss: 3.8938728       8.2277239\n",
      "[131/1000] loss: 3.8842179       7.7795577\n",
      "[132/1000] loss: 3.8717371       7.3451149\n",
      "[133/1000] loss: 3.8812794       7.3922946\n",
      "[134/1000] loss: 3.8659622       7.3966534\n",
      "[135/1000] loss: 3.8652676       7.3578213\n",
      "[136/1000] loss: 3.856869       7.7371435\n",
      "[137/1000] loss: 3.852036       8.113222\n",
      "[138/1000] loss: 3.8324202       7.5127212\n",
      "[139/1000] loss: 3.8354775       7.3241816\n",
      "[140/1000] loss: 3.8475056       7.9416989\n",
      "[141/1000] loss: 3.8290201       7.6341969\n",
      "[142/1000] loss: 3.8214589       7.688658\n",
      "[143/1000] loss: 3.8046417       7.6664633\n",
      "[144/1000] loss: 3.8002711       7.2411203\n",
      "[145/1000] loss: 3.8164118       8.014537\n",
      "[146/1000] loss: 3.8257454       7.2310698\n",
      "[147/1000] loss: 3.7858495       7.2953046\n",
      "[148/1000] loss: 3.773002       8.8310112\n",
      "[149/1000] loss: 3.7627295       7.4953762\n",
      "[150/1000] loss: 3.7587034       7.9545335\n",
      "[151/1000] loss: 3.7631056       8.172771\n",
      "[152/1000] loss: 3.7595225       7.4223545\n",
      "[153/1000] loss: 3.7471363       7.23621\n",
      "[154/1000] loss: 3.7424979       7.1872966\n",
      "[155/1000] loss: 3.7420456       7.2326717\n",
      "[156/1000] loss: 3.7242659       7.2516111\n",
      "[157/1000] loss: 3.7376459       7.1470743\n",
      "[158/1000] loss: 3.7204569       7.118131\n",
      "[159/1000] loss: 3.7319843       7.1370496\n",
      "[160/1000] loss: 3.719098       7.8491736\n",
      "[161/1000] loss: 3.7029495       7.9468456\n",
      "[162/1000] loss: 3.7143054       7.3265783\n",
      "[163/1000] loss: 3.7237999       7.129506\n",
      "[164/1000] loss: 3.6895619       8.6137043\n",
      "[165/1000] loss: 3.6883579       7.0931979\n",
      "[166/1000] loss: 3.6856017       7.3357646\n",
      "[167/1000] loss: 3.6711035       7.4937551\n",
      "[168/1000] loss: 3.6692528       7.3187786\n",
      "[169/1000] loss: 3.6640574       7.1184299\n",
      "[170/1000] loss: 3.6658125       7.2726978\n",
      "[171/1000] loss: 3.6688339       7.2338684\n",
      "[172/1000] loss: 3.6549839       7.6745134\n",
      "[173/1000] loss: 3.6505169       7.0307189\n",
      "[174/1000] loss: 3.6590981       7.0167634\n",
      "[175/1000] loss: 3.6413836       8.5363825\n",
      "[176/1000] loss: 3.6404243       7.0264276\n",
      "[177/1000] loss: 3.623909       7.3085605\n",
      "[178/1000] loss: 3.6215327       7.6960733\n",
      "[179/1000] loss: 3.6238532       7.206053\n",
      "[180/1000] loss: 3.6261086       10.05285\n",
      "[181/1000] loss: 3.6189656       8.7611837\n",
      "[182/1000] loss: 3.6122182       7.2692587\n",
      "[183/1000] loss: 3.6002398       7.6286701\n",
      "[184/1000] loss: 3.6153666       7.6761977\n",
      "[185/1000] loss: 3.6307629       6.9586951\n",
      "[186/1000] loss: 3.5851455       6.9955965\n",
      "[187/1000] loss: 3.5804412       7.7566974\n",
      "[188/1000] loss: 3.5769576       7.3903914\n",
      "[189/1000] loss: 3.5739126       6.9081858\n",
      "[190/1000] loss: 3.5885397       7.2375901\n",
      "[191/1000] loss: 3.5895196       8.4209868\n",
      "[192/1000] loss: 3.5598285       7.5268023\n",
      "[193/1000] loss: 3.5727006       7.0889829\n",
      "[194/1000] loss: 3.5574587       6.8618004\n",
      "[195/1000] loss: 3.5709402       7.0929742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196/1000] loss: 3.5435485       7.1106683\n",
      "[197/1000] loss: 3.5364219       6.8588297\n",
      "[198/1000] loss: 3.5381177       8.9550452\n",
      "[199/1000] loss: 3.5346552       6.8240727\n",
      "[200/1000] loss: 3.5217407       7.1049543\n",
      "[201/1000] loss: 3.5243512       6.810643\n",
      "[202/1000] loss: 3.5211361       6.8273322\n",
      "[203/1000] loss: 3.5187434       7.3574011\n",
      "[204/1000] loss: 3.5146871       6.7805717\n",
      "[205/1000] loss: 3.5392854       6.8075629\n",
      "[206/1000] loss: 3.4997225       7.0728681\n",
      "[207/1000] loss: 3.5212465       7.0482086\n",
      "[208/1000] loss: 3.5002189       7.3617537\n",
      "[209/1000] loss: 3.5109346       6.931252\n",
      "[210/1000] loss: 3.4848007       6.7759831\n",
      "[211/1000] loss: 3.4902636       7.3342137\n",
      "[212/1000] loss: 3.4841602       7.0467719\n",
      "[213/1000] loss: 3.4624988       7.2597145\n",
      "[214/1000] loss: 3.4624598       6.7121978\n",
      "[215/1000] loss: 3.448531       8.4676175\n",
      "[216/1000] loss: 3.4542349       6.907138\n",
      "[217/1000] loss: 3.4615812       6.7027742\n",
      "[218/1000] loss: 3.4338467       6.8689722\n",
      "[219/1000] loss: 3.4302486       8.15358\n",
      "[220/1000] loss: 3.4242269       6.6760593\n",
      "[221/1000] loss: 3.4280697       6.7036089\n",
      "[222/1000] loss: 3.4069863       6.6105325\n",
      "[223/1000] loss: 3.4209183       6.5906191\n",
      "[224/1000] loss: 3.4007558       6.6263792\n",
      "[225/1000] loss: 3.3974422       7.0249114\n",
      "[226/1000] loss: 3.4011001       6.6011637\n",
      "[227/1000] loss: 3.3912711       6.6103285\n",
      "[228/1000] loss: 3.3897114       6.5719746\n",
      "[229/1000] loss: 3.3835151       6.6156158\n",
      "[230/1000] loss: 3.3784397       8.0470656\n",
      "[231/1000] loss: 3.3737712       6.5458311\n",
      "[232/1000] loss: 3.3848029       6.5353808\n",
      "[233/1000] loss: 3.3773193       7.3734106\n",
      "[234/1000] loss: 3.3614025       7.4074971\n",
      "[235/1000] loss: 3.344316       7.6071628\n",
      "[236/1000] loss: 3.3379716       7.2309947\n",
      "[237/1000] loss: 3.3325549       7.9974914\n",
      "[238/1000] loss: 3.3279633       6.6442662\n",
      "[239/1000] loss: 3.3673277       6.9485888\n",
      "[240/1000] loss: 3.3230836       6.6925719\n",
      "[241/1000] loss: 3.3536212       6.4966888\n",
      "[242/1000] loss: 3.3043469       6.492625\n",
      "[243/1000] loss: 3.3175787       6.4413739\n",
      "[244/1000] loss: 3.298778       6.5505167\n",
      "[245/1000] loss: 3.3017761       6.4571102\n",
      "[246/1000] loss: 3.2988702       6.44739\n",
      "[247/1000] loss: 3.3001459       6.4854728\n",
      "[248/1000] loss: 3.2970857       7.0510699\n",
      "[249/1000] loss: 3.2710307       8.659643\n",
      "[250/1000] loss: 3.2641555       6.4330637\n",
      "[251/1000] loss: 3.2764453       6.6411614\n",
      "[252/1000] loss: 3.2617315       6.495468\n",
      "[253/1000] loss: 3.2490179       7.4397202\n",
      "[254/1000] loss: 3.2469192       6.6339127\n",
      "[255/1000] loss: 3.246884       6.6107878\n",
      "[256/1000] loss: 3.2514574       6.3970619\n",
      "[257/1000] loss: 3.2345604       6.3811107\n",
      "[258/1000] loss: 3.2305425       6.55019\n",
      "[259/1000] loss: 3.2255626       6.3683819\n",
      "[260/1000] loss: 3.2318611       7.3272427\n",
      "[261/1000] loss: 3.2212       7.1515952\n",
      "[262/1000] loss: 3.2102024       6.6313174\n",
      "[263/1000] loss: 3.2061242       6.3516988\n",
      "[264/1000] loss: 3.1987804       6.5446685\n",
      "[265/1000] loss: 3.1985082       6.8084828\n",
      "[266/1000] loss: 3.1868454       6.3306683\n",
      "[267/1000] loss: 3.1890491       6.3066992\n",
      "[268/1000] loss: 3.1944785       6.2897346\n",
      "[269/1000] loss: 3.1901496       7.5159654\n",
      "[270/1000] loss: 3.1767564       6.2861182\n",
      "[271/1000] loss: 3.1596895       6.2656954\n",
      "[272/1000] loss: 3.1609013       9.1165957\n",
      "[273/1000] loss: 3.1667354       6.2687998\n",
      "[274/1000] loss: 3.1687178       6.6386692\n",
      "[275/1000] loss: 3.1466755       6.2204034\n",
      "[276/1000] loss: 3.1368262       7.6775152\n",
      "[277/1000] loss: 3.1402972       6.7292018\n",
      "[278/1000] loss: 3.1255085       6.5337515\n",
      "[279/1000] loss: 3.1161846       6.5643581\n",
      "[280/1000] loss: 3.1160086       6.3882017\n",
      "[281/1000] loss: 3.1272748       6.1975396\n",
      "[282/1000] loss: 3.1155763       6.1857268\n",
      "[283/1000] loss: 3.1021878       6.2054643\n",
      "[284/1000] loss: 3.1105672       6.1858804\n",
      "[285/1000] loss: 3.0950446       6.7837982\n",
      "[286/1000] loss: 3.0877821       6.2520015\n",
      "[287/1000] loss: 3.0776225       6.1476459\n",
      "[288/1000] loss: 3.0874747       6.1443758\n",
      "[289/1000] loss: 3.0944026       6.1326172\n",
      "[290/1000] loss: 3.0613136       6.2557116\n",
      "[291/1000] loss: 3.0611346       6.1045867\n",
      "[292/1000] loss: 3.0688724       6.1017438\n",
      "[293/1000] loss: 3.0589252       6.0796237\n",
      "[294/1000] loss: 3.0448433       7.4940891\n",
      "[295/1000] loss: 3.0387217       6.071518\n",
      "[296/1000] loss: 3.0718616       6.0514939\n",
      "[297/1000] loss: 3.0252798       6.4156282\n",
      "[298/1000] loss: 3.0181581       6.4461792\n",
      "[299/1000] loss: 3.023004       6.5391907\n",
      "[300/1000] loss: 3.0060641       6.2618033\n",
      "[301/1000] loss: 3.0102346       6.8083885\n",
      "[302/1000] loss: 3.0120981       6.3247315\n",
      "[303/1000] loss: 3.0083904       6.0209246\n",
      "[304/1000] loss: 2.9906495       5.9887772\n",
      "[305/1000] loss: 2.9839255       7.5757263\n",
      "[306/1000] loss: 2.9829393       6.0054468\n",
      "[307/1000] loss: 2.9729375       6.2653108\n",
      "[308/1000] loss: 2.960957       6.0000762\n",
      "[309/1000] loss: 2.9592441       7.3380569\n",
      "[310/1000] loss: 2.9553573       6.9631071\n",
      "[311/1000] loss: 2.9492849       6.7274482\n",
      "[312/1000] loss: 2.9485117       6.0044827\n",
      "[313/1000] loss: 2.9471697       7.5388272\n",
      "[314/1000] loss: 2.9427513       6.499427\n",
      "[315/1000] loss: 2.9414158       7.5649514\n",
      "[316/1000] loss: 2.9350315       6.356448\n",
      "[317/1000] loss: 2.9451122       6.1405781\n",
      "[318/1000] loss: 2.9303772       6.0439166\n",
      "[319/1000] loss: 2.9097453       6.9953614\n",
      "[320/1000] loss: 2.9144808       5.8902651\n",
      "[321/1000] loss: 2.8988937       6.2244248\n",
      "[322/1000] loss: 2.8957126       6.1631942\n",
      "[323/1000] loss: 2.885691       5.8341897\n",
      "[324/1000] loss: 2.8756629       6.6416339\n",
      "[325/1000] loss: 2.8673027       6.5491876\n",
      "[326/1000] loss: 2.8801454       5.848573\n",
      "[327/1000] loss: 2.8806807       5.8266173\n",
      "[328/1000] loss: 2.8551234       5.7745301\n",
      "[329/1000] loss: 2.8467716       6.1541466\n",
      "[330/1000] loss: 2.8619895       5.9782292\n",
      "[331/1000] loss: 2.8626775       5.9797581\n",
      "[332/1000] loss: 2.841835       5.7720732\n",
      "[333/1000] loss: 2.8324698       5.8661119\n",
      "[334/1000] loss: 2.8148239       5.8142716\n",
      "[335/1000] loss: 2.8104163       5.7412299\n",
      "[336/1000] loss: 2.8151163       6.0575023\n",
      "[337/1000] loss: 2.8046171       5.8641667\n",
      "[338/1000] loss: 2.7931781       6.3390282\n",
      "[339/1000] loss: 2.8024057       5.841584\n",
      "[340/1000] loss: 2.7863811       7.0639092\n",
      "[341/1000] loss: 2.7841969       5.7214776\n",
      "[342/1000] loss: 2.8004096       6.0845071\n",
      "[343/1000] loss: 2.7801318       5.6629342\n",
      "[344/1000] loss: 2.7718968       5.6965154\n",
      "[345/1000] loss: 2.7714592       5.9404403\n",
      "[346/1000] loss: 2.7577436       5.6611171\n",
      "[347/1000] loss: 2.7463138       6.988535\n",
      "[348/1000] loss: 2.7480135       6.3654738\n",
      "[349/1000] loss: 2.7622068       5.7808364\n",
      "[350/1000] loss: 2.7324864       5.6522722\n",
      "[351/1000] loss: 2.7334468       5.8565028\n",
      "[352/1000] loss: 2.7580268       5.6096311\n",
      "[353/1000] loss: 2.7322641       6.1478929\n",
      "[354/1000] loss: 2.7252516       5.5526629\n",
      "[355/1000] loss: 2.7110963       5.5536078\n",
      "[356/1000] loss: 2.7098593       5.535859\n",
      "[357/1000] loss: 2.6929689       5.8285459\n",
      "[358/1000] loss: 2.6826244       6.2318158\n",
      "[359/1000] loss: 2.6902696       5.5149217\n",
      "[360/1000] loss: 2.6825862       5.9056507\n",
      "[361/1000] loss: 2.6753192       5.6454213\n",
      "[362/1000] loss: 2.6633935       6.5262595\n",
      "[363/1000] loss: 2.6822802       5.5194167\n",
      "[364/1000] loss: 2.6547379       5.4550069\n",
      "[365/1000] loss: 2.6488205       5.5488013\n",
      "[366/1000] loss: 2.6648895       5.8437112\n",
      "[367/1000] loss: 2.6633505       5.7237891\n",
      "[368/1000] loss: 2.6371815       6.2521744\n",
      "[369/1000] loss: 2.6462117       6.1601215\n",
      "[370/1000] loss: 2.6238254       5.4476729\n",
      "[371/1000] loss: 2.6240688       5.4289951\n",
      "[372/1000] loss: 2.6250957       5.746784\n",
      "[373/1000] loss: 2.6235392       5.4749164\n",
      "[374/1000] loss: 2.6105257       5.825462\n",
      "[375/1000] loss: 2.6131557       5.4029008\n",
      "[376/1000] loss: 2.5985961       5.4413497\n",
      "[377/1000] loss: 2.5900016       5.3387573\n",
      "[378/1000] loss: 2.5892047       5.4479679\n",
      "[379/1000] loss: 2.5906592       5.3517564\n",
      "[380/1000] loss: 2.5768257       5.4437405\n",
      "[381/1000] loss: 2.5794312       5.3001396\n",
      "[382/1000] loss: 2.5792774       5.3316747\n",
      "[383/1000] loss: 2.5670774       5.2937759\n",
      "[384/1000] loss: 2.5631049       5.2845285\n",
      "[385/1000] loss: 2.5586148       5.6590312\n",
      "[386/1000] loss: 2.5415764       5.3045123\n",
      "[387/1000] loss: 2.5452215       5.2745576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[388/1000] loss: 2.5550925       5.3892206\n",
      "[389/1000] loss: 2.5317115       5.2430064\n",
      "[390/1000] loss: 2.5336466       5.2509426\n",
      "[391/1000] loss: 2.5456079       5.6056908\n",
      "[392/1000] loss: 2.54515       5.4408692\n",
      "[393/1000] loss: 2.5092395       5.4516126\n",
      "[394/1000] loss: 2.5085259       5.3378981\n",
      "[395/1000] loss: 2.5006578       5.3873445\n",
      "[396/1000] loss: 2.4923423       5.3075988\n",
      "[397/1000] loss: 2.4908376       5.1973592\n",
      "[398/1000] loss: 2.4819206       5.1725991\n",
      "[399/1000] loss: 2.485943       5.4211508\n",
      "[400/1000] loss: 2.4750542       5.4115548\n",
      "[401/1000] loss: 2.467896       5.3015356\n",
      "[402/1000] loss: 2.476533       5.8657438\n",
      "[403/1000] loss: 2.4877145       5.8080038\n",
      "[404/1000] loss: 2.4586632       5.1268328\n",
      "[405/1000] loss: 2.4567414       5.7946601\n",
      "[406/1000] loss: 2.4474217       5.1266799\n",
      "[407/1000] loss: 2.4433827       5.3045373\n",
      "[408/1000] loss: 2.4349745       5.3718499\n",
      "[409/1000] loss: 2.4480711       5.2132917\n",
      "[410/1000] loss: 2.433877       5.4743433\n",
      "[411/1000] loss: 2.4430101       5.0665281\n",
      "[412/1000] loss: 2.4425441       5.0582608\n",
      "[413/1000] loss: 2.4191165       5.1001786\n",
      "[414/1000] loss: 2.4216575       5.5184418\n",
      "[415/1000] loss: 2.4062658       5.2537064\n",
      "[416/1000] loss: 2.4293007       6.3433067\n",
      "[417/1000] loss: 2.4043432       5.361543\n",
      "[418/1000] loss: 2.3909146       6.2983771\n",
      "[419/1000] loss: 2.3851513       6.4166043\n",
      "[420/1000] loss: 2.3835298       5.0129132\n",
      "[421/1000] loss: 2.3881849       5.1268821\n",
      "[422/1000] loss: 2.3747019       4.9948096\n",
      "[423/1000] loss: 2.3694531       4.978571\n",
      "[424/1000] loss: 2.3682757       5.9969558\n",
      "[425/1000] loss: 2.3573335       4.9772892\n",
      "[426/1000] loss: 2.3644474       4.9660552\n",
      "[427/1000] loss: 2.3592696       5.7502028\n",
      "[428/1000] loss: 2.354578       5.1279794\n",
      "[429/1000] loss: 2.3505163       5.0661075\n",
      "[430/1000] loss: 2.3424115       4.9410382\n",
      "[431/1000] loss: 2.3311016       5.2689696\n",
      "[432/1000] loss: 2.3490599       5.5464196\n",
      "[433/1000] loss: 2.3276613       4.9761649\n",
      "[434/1000] loss: 2.3193085       4.8976354\n",
      "[435/1000] loss: 2.3183671       5.1756085\n",
      "[436/1000] loss: 2.3246682       4.9012673\n",
      "[437/1000] loss: 2.3125989       5.0274486\n",
      "[438/1000] loss: 2.3035757       6.1667264\n",
      "[439/1000] loss: 2.3065945       4.86706\n",
      "[440/1000] loss: 2.2985032       5.053025\n",
      "[441/1000] loss: 2.2927317       4.9749453\n",
      "[442/1000] loss: 2.2942092       4.8651658\n",
      "[443/1000] loss: 2.2848396       5.167949\n",
      "[444/1000] loss: 2.2851406       4.9355985\n",
      "[445/1000] loss: 2.2726938       6.3350006\n",
      "[446/1000] loss: 2.2804538       4.9039462\n",
      "[447/1000] loss: 2.2694074       4.7987204\n",
      "[448/1000] loss: 2.2762172       4.8411855\n",
      "[449/1000] loss: 2.2577185       5.1283047\n",
      "[450/1000] loss: 2.2657738       5.0661261\n",
      "[451/1000] loss: 2.2795655       5.4433337\n",
      "[452/1000] loss: 2.2523736       5.1121594\n",
      "[453/1000] loss: 2.2508237       5.1326496\n",
      "[454/1000] loss: 2.24353       4.8219302\n",
      "[455/1000] loss: 2.2431303       4.9572719\n",
      "[456/1000] loss: 2.2328086       4.7889083\n",
      "[457/1000] loss: 2.2388514       4.7137487\n",
      "[458/1000] loss: 2.2284954       5.0640101\n",
      "[459/1000] loss: 2.2257493       4.7085465\n",
      "[460/1000] loss: 2.2423476       4.8158792\n",
      "[461/1000] loss: 2.2121698       4.8970497\n",
      "[462/1000] loss: 2.2109982       4.813613\n",
      "[463/1000] loss: 2.217681       4.7532253\n",
      "[464/1000] loss: 2.2013186       6.0460805\n",
      "[465/1000] loss: 2.2016522       4.6948551\n",
      "[466/1000] loss: 2.2126543       4.8999055\n",
      "[467/1000] loss: 2.1955173       4.7656406\n",
      "[468/1000] loss: 2.1976952       4.6611849\n",
      "[469/1000] loss: 2.1872235       5.2646623\n",
      "[470/1000] loss: 2.1867849       4.7591313\n",
      "[471/1000] loss: 2.1901496       4.6241283\n",
      "[472/1000] loss: 2.1884637       5.8503809\n",
      "[473/1000] loss: 2.1969501       4.6404766\n",
      "[474/1000] loss: 2.1673205       4.6214431\n",
      "[475/1000] loss: 2.1791358       4.6727839\n",
      "[476/1000] loss: 2.1548113       4.6703936\n",
      "[477/1000] loss: 2.1747267       4.6466952\n",
      "[478/1000] loss: 2.1566443       5.7322796\n",
      "[479/1000] loss: 2.1623025       4.6028863\n",
      "[480/1000] loss: 2.1802665       4.8507346\n",
      "[481/1000] loss: 2.1462579       4.8997714\n",
      "[482/1000] loss: 2.1424687       4.99981\n",
      "[483/1000] loss: 2.1521327       4.5627533\n",
      "[484/1000] loss: 2.1347624       4.5523393\n",
      "[485/1000] loss: 2.1257869       4.5590184\n",
      "[486/1000] loss: 2.126734       4.5302359\n",
      "[487/1000] loss: 2.1234922       4.5993599\n",
      "[488/1000] loss: 2.1421227       4.7059855\n",
      "[489/1000] loss: 2.1226143       4.5897084\n",
      "[490/1000] loss: 2.1174663       4.5368252\n",
      "[491/1000] loss: 2.1165057       4.5528976\n",
      "[492/1000] loss: 2.1169592       4.5611454\n",
      "[493/1000] loss: 2.1022601       5.0610592\n",
      "[494/1000] loss: 2.1101356       4.5760201\n",
      "[495/1000] loss: 2.1032974       4.5502258\n",
      "[496/1000] loss: 2.0979314       5.6454603\n",
      "[497/1000] loss: 2.0902077       4.7976412\n",
      "[498/1000] loss: 2.089472       4.4598149\n",
      "[499/1000] loss: 2.0829864       4.4676029\n",
      "[500/1000] loss: 2.0806131       4.6412255\n",
      "[501/1000] loss: 2.0802441       4.4622545\n",
      "[502/1000] loss: 2.0804483       4.4667256\n",
      "[503/1000] loss: 2.0802821       5.6199336\n",
      "[504/1000] loss: 2.0730417       4.4882403\n",
      "[505/1000] loss: 2.0801356       4.4162284\n",
      "[506/1000] loss: 2.0716451       4.6260069\n",
      "[507/1000] loss: 2.0597549       4.6283911\n",
      "[508/1000] loss: 2.0632658       4.7188859\n",
      "[509/1000] loss: 2.0599637       4.46734\n",
      "[510/1000] loss: 2.0550945       4.3896621\n",
      "[511/1000] loss: 2.0498135       4.4076162\n",
      "[512/1000] loss: 2.0618206       5.0830789\n",
      "[513/1000] loss: 2.0550508       4.421038\n",
      "[514/1000] loss: 2.0473388       4.3698279\n",
      "[515/1000] loss: 2.0457337       5.5558714\n",
      "[516/1000] loss: 2.0507632       4.3860168\n",
      "[517/1000] loss: 2.0546631       4.6311289\n",
      "[518/1000] loss: 2.0311266       4.5416816\n",
      "[519/1000] loss: 2.0342583       5.4502678\n",
      "[520/1000] loss: 2.0302682       4.3936002\n",
      "[521/1000] loss: 2.0268619       4.3469347\n",
      "[522/1000] loss: 2.0333856       4.3645999\n",
      "[523/1000] loss: 2.0385377       4.3767653\n",
      "[524/1000] loss: 2.0266466       4.9139478\n",
      "[525/1000] loss: 2.0473469       5.5176149\n",
      "[526/1000] loss: 2.0117692       4.3162642\n",
      "[527/1000] loss: 2.0156691       4.3372143\n",
      "[528/1000] loss: 2.0164548       4.3048982\n",
      "[529/1000] loss: 2.0309516       4.7009028\n",
      "[530/1000] loss: 2.0076334       4.59033\n",
      "[531/1000] loss: 2.0033749       4.4934155\n",
      "[532/1000] loss: 1.9993133       4.3083625\n",
      "[533/1000] loss: 2.0013512       4.3023383\n",
      "[534/1000] loss: 1.9977443       5.5352169\n",
      "[535/1000] loss: 2.0340343       4.3204545\n",
      "[536/1000] loss: 1.9866288       4.331336\n",
      "[537/1000] loss: 1.9888655       4.41484\n",
      "[538/1000] loss: 1.9924995       5.3466934\n",
      "[539/1000] loss: 1.9839624       4.8708413\n",
      "[540/1000] loss: 1.9884101       4.4392355\n",
      "[541/1000] loss: 1.9783468       4.2598348\n",
      "[542/1000] loss: 1.9869408       4.7934648\n",
      "[543/1000] loss: 1.9859365       4.2445338\n",
      "[544/1000] loss: 1.9768844       4.5059559\n",
      "[545/1000] loss: 1.973418       4.2898343\n",
      "[546/1000] loss: 1.9706187       4.2242912\n",
      "[547/1000] loss: 1.9665251       4.2769199\n",
      "[548/1000] loss: 1.9644549       4.4706852\n",
      "[549/1000] loss: 1.9708489       4.2082616\n",
      "[550/1000] loss: 1.96327       4.3759446\n",
      "[551/1000] loss: 1.9643842       4.2208854\n",
      "[552/1000] loss: 1.958958       4.2704037\n",
      "[553/1000] loss: 1.9591102       4.2110899\n",
      "[554/1000] loss: 1.9614714       4.2975195\n",
      "[555/1000] loss: 1.9545845       5.7583285\n",
      "[556/1000] loss: 1.9549608       4.2379394\n",
      "[557/1000] loss: 1.9507743       4.174788\n",
      "[558/1000] loss: 1.9454672       4.4420487\n",
      "[559/1000] loss: 1.9502074       4.2090781\n",
      "[560/1000] loss: 1.9458407       4.407836\n",
      "[561/1000] loss: 1.9376757       4.3375416\n",
      "[562/1000] loss: 1.9445849       4.1561735\n",
      "[563/1000] loss: 1.9373442       4.1867209\n",
      "[564/1000] loss: 1.9334417       4.3975052\n",
      "[565/1000] loss: 1.9603111       4.5100049\n",
      "[566/1000] loss: 1.9310851       4.1883154\n",
      "[567/1000] loss: 1.9302966       4.2575893\n",
      "[568/1000] loss: 1.9289829       4.1387269\n",
      "[569/1000] loss: 1.9270828       4.1757982\n",
      "[570/1000] loss: 1.9260464       4.13723\n",
      "[571/1000] loss: 1.9207952       4.322707\n",
      "[572/1000] loss: 1.9167023       4.2999622\n",
      "[573/1000] loss: 1.9187276       4.1015426\n",
      "[574/1000] loss: 1.9179479       4.1345568\n",
      "[575/1000] loss: 1.9244108       4.1744094\n",
      "[576/1000] loss: 1.9134784       4.2216378\n",
      "[577/1000] loss: 1.9131032       4.1952914\n",
      "[578/1000] loss: 1.9176137       4.163457\n",
      "[579/1000] loss: 1.9133119       4.0902659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[580/1000] loss: 1.9173523       4.2346006\n",
      "[581/1000] loss: 1.9084532       4.2297412\n",
      "[582/1000] loss: 1.9240413       5.1417726\n",
      "[583/1000] loss: 1.903066       5.129113\n",
      "[584/1000] loss: 1.914882       4.2026922\n",
      "[585/1000] loss: 1.9018609       4.0806609\n",
      "[586/1000] loss: 1.9038187       4.1176462\n",
      "[587/1000] loss: 1.8952965       4.1351389\n",
      "[588/1000] loss: 1.8930425       4.0590771\n",
      "[589/1000] loss: 1.8953364       4.0638969\n",
      "[590/1000] loss: 1.887349       4.1061004\n",
      "[591/1000] loss: 1.8864683       4.0615641\n",
      "[592/1000] loss: 1.8867509       4.1257322\n",
      "[593/1000] loss: 1.8909446       4.0668471\n",
      "[594/1000] loss: 1.888606       4.4132655\n",
      "[595/1000] loss: 1.8784264       4.0694171\n",
      "[596/1000] loss: 1.8945558       4.5039503\n",
      "[597/1000] loss: 1.8824249       4.0767717\n",
      "[598/1000] loss: 1.8739983       4.1854489\n",
      "[599/1000] loss: 1.8802975       4.4122376\n",
      "[600/1000] loss: 1.8769776       4.254776\n",
      "[601/1000] loss: 1.8743211       4.0166825\n",
      "[602/1000] loss: 1.8650032       4.1502162\n",
      "[603/1000] loss: 1.8788212       4.0229772\n",
      "[604/1000] loss: 1.8739093       4.018139\n",
      "[605/1000] loss: 1.8685358       4.2998544\n",
      "[606/1000] loss: 1.8758099       3.9900262\n",
      "[607/1000] loss: 1.8700445       4.7593317\n",
      "[608/1000] loss: 1.8673788       4.0734901\n",
      "[609/1000] loss: 1.8655541       3.9814511\n",
      "[610/1000] loss: 1.8586476       3.9972666\n",
      "[611/1000] loss: 1.8722634       4.1078021\n",
      "[612/1000] loss: 1.8535881       4.3727596\n",
      "[613/1000] loss: 1.856494       4.0430657\n",
      "[614/1000] loss: 1.8525685       4.0092318\n",
      "[615/1000] loss: 1.8616635       4.004373\n",
      "[616/1000] loss: 1.8565676       3.9630754\n",
      "[617/1000] loss: 1.8484221       3.976678\n",
      "[618/1000] loss: 1.8541367       4.007032\n",
      "[619/1000] loss: 1.8488737       4.1205312\n",
      "[620/1000] loss: 1.846832       4.0856725\n",
      "[621/1000] loss: 1.8402098       3.9959905\n",
      "[622/1000] loss: 1.8452324       4.0039189\n",
      "[623/1000] loss: 1.8422383       4.0975175\n",
      "[624/1000] loss: 1.8390619       4.5120722\n",
      "[625/1000] loss: 1.8405963       4.1114569\n",
      "[626/1000] loss: 1.8417834       4.1144358\n",
      "[627/1000] loss: 1.8378838       3.978946\n",
      "[628/1000] loss: 1.8463652       3.9773683\n",
      "[629/1000] loss: 1.8386504       4.3029506\n",
      "[630/1000] loss: 1.8322562       4.0790924\n",
      "[631/1000] loss: 1.8659738       4.0139169\n",
      "[632/1000] loss: 1.8333503       3.931979\n",
      "[633/1000] loss: 1.8307803       3.9896516\n",
      "[634/1000] loss: 1.8299939       4.1316903\n",
      "[635/1000] loss: 1.8318736       4.0071148\n",
      "[636/1000] loss: 1.8338283       3.9461289\n",
      "[637/1000] loss: 1.8335619       3.8991874\n",
      "[638/1000] loss: 1.8240427       4.8895597\n",
      "[639/1000] loss: 1.8215726       5.0056802\n",
      "[640/1000] loss: 1.824895       4.0223914\n",
      "[641/1000] loss: 1.8185451       3.9014924\n",
      "[642/1000] loss: 1.8194996       3.9738443\n",
      "[643/1000] loss: 1.8169066       4.3622975\n",
      "[644/1000] loss: 1.8176539       4.0069861\n",
      "[645/1000] loss: 1.8159713       3.9866387\n",
      "[646/1000] loss: 1.8177011       4.3334931\n",
      "[647/1000] loss: 1.8133196       4.0231615\n",
      "[648/1000] loss: 1.8180301       4.2181933\n",
      "[649/1000] loss: 1.8090723       3.8863213\n",
      "[650/1000] loss: 1.8195216       4.0663235\n",
      "[651/1000] loss: 1.8068637       3.869252\n",
      "[652/1000] loss: 1.8052849       3.911214\n",
      "[653/1000] loss: 1.8131653       4.1076176\n",
      "[654/1000] loss: 1.8061094       4.1415543\n",
      "[655/1000] loss: 1.8064249       4.8615064\n",
      "[656/1000] loss: 1.7994826       3.9137975\n",
      "[657/1000] loss: 1.8216143       3.9998044\n",
      "[658/1000] loss: 1.8090805       3.9323479\n",
      "[659/1000] loss: 1.7994002       4.0267945\n",
      "[660/1000] loss: 1.7982836       3.9629357\n",
      "[661/1000] loss: 1.7997353       3.8576816\n",
      "[662/1000] loss: 1.802606       4.0112991\n",
      "[663/1000] loss: 1.7948109       3.9304774\n",
      "[664/1000] loss: 1.7956932       3.8451116\n",
      "[665/1000] loss: 1.8079686       3.817539\n",
      "[666/1000] loss: 1.7950846       3.8395627\n",
      "[667/1000] loss: 1.7924059       3.8984443\n",
      "[668/1000] loss: 1.7887831       4.1666996\n",
      "[669/1000] loss: 1.788619       3.8214525\n",
      "[670/1000] loss: 1.7899099       3.8361756\n",
      "[671/1000] loss: 1.7986627       3.9194318\n",
      "[672/1000] loss: 1.788178       3.8190665\n",
      "[673/1000] loss: 1.7835726       3.8162173\n",
      "[674/1000] loss: 1.7864861       4.7687226\n",
      "[675/1000] loss: 1.7931787       3.8321475\n",
      "[676/1000] loss: 1.7860505       4.0263838\n",
      "[677/1000] loss: 1.7794396       4.7827119\n",
      "[678/1000] loss: 1.780566       3.9595079\n",
      "[679/1000] loss: 1.7871348       3.8367408\n",
      "[680/1000] loss: 1.7787755       3.832386\n",
      "[681/1000] loss: 1.8051633       4.0907154\n",
      "[682/1000] loss: 1.7779943       3.8654595\n",
      "[683/1000] loss: 1.7735172       3.8025014\n",
      "[684/1000] loss: 1.7746599       3.9999465\n",
      "[685/1000] loss: 1.7779489       3.9693197\n",
      "[686/1000] loss: 1.7707649       3.7732039\n",
      "[687/1000] loss: 1.7991663       3.7877045\n",
      "[688/1000] loss: 1.7709429       4.0165808\n",
      "[689/1000] loss: 1.7757804       3.7874001\n",
      "[690/1000] loss: 1.7673853       3.8936823\n",
      "[691/1000] loss: 1.7735777       3.8013264\n",
      "[692/1000] loss: 1.7659211       3.8998363\n",
      "[693/1000] loss: 1.7726199       3.9566992\n",
      "[694/1000] loss: 1.7721877       3.7514091\n",
      "[695/1000] loss: 1.762671       3.7690756\n",
      "[696/1000] loss: 1.7707889       3.9158262\n",
      "[697/1000] loss: 1.7695664       3.8063192\n",
      "[698/1000] loss: 1.7805726       4.1635471\n",
      "[699/1000] loss: 1.7623295       4.1765417\n",
      "[700/1000] loss: 1.7574075       3.8649597\n",
      "[701/1000] loss: 1.7587406       3.8823825\n",
      "[702/1000] loss: 1.766035       4.3777728\n",
      "[703/1000] loss: 1.7542142       3.7482173\n",
      "[704/1000] loss: 1.7584762       4.2018871\n",
      "[705/1000] loss: 1.7587999       4.8053053\n",
      "[706/1000] loss: 1.7514988       3.7296885\n",
      "[707/1000] loss: 1.7515926       4.1203743\n",
      "[708/1000] loss: 1.7537956       3.8372221\n",
      "[709/1000] loss: 1.7477403       3.7468765\n",
      "[710/1000] loss: 1.7462251       4.7101724\n",
      "[711/1000] loss: 1.7489775       3.9113501\n",
      "[712/1000] loss: 1.7528428       3.9706876\n",
      "[713/1000] loss: 1.7498574       3.7695709\n",
      "[714/1000] loss: 1.7605462       3.8789588\n",
      "[715/1000] loss: 1.74807       3.7101204\n",
      "[716/1000] loss: 1.7492253       4.0821914\n",
      "[717/1000] loss: 1.749792       4.2917332\n",
      "[718/1000] loss: 1.7403105       4.1165788\n",
      "[719/1000] loss: 1.7427087       3.7109759\n",
      "[720/1000] loss: 1.7381162       3.9691155\n",
      "[721/1000] loss: 1.7373915       4.1169068\n",
      "[722/1000] loss: 1.7430306       4.7429163\n",
      "[723/1000] loss: 1.7355772       3.6885692\n",
      "[724/1000] loss: 1.7323682       3.7452699\n",
      "[725/1000] loss: 1.749968       3.9124384\n",
      "[726/1000] loss: 1.7701603       4.7216897\n",
      "[727/1000] loss: 1.753695       4.3638653\n",
      "[728/1000] loss: 1.7370959       4.6554659\n",
      "[729/1000] loss: 1.7445237       3.7490735\n",
      "[730/1000] loss: 1.7360167       3.7276473\n",
      "[731/1000] loss: 1.7294478       3.789843\n",
      "[732/1000] loss: 1.7263532       3.7297051\n",
      "[733/1000] loss: 1.7467268       3.9675367\n",
      "[734/1000] loss: 1.7283314       4.6884829\n",
      "[735/1000] loss: 1.7263919       3.8309887\n",
      "[736/1000] loss: 1.7333664       3.7860957\n",
      "[737/1000] loss: 1.7371446       3.8861056\n",
      "[738/1000] loss: 1.7271888       3.8863807\n",
      "[739/1000] loss: 1.7228125       4.1406365\n",
      "[740/1000] loss: 1.7328311       3.6605032\n",
      "[741/1000] loss: 1.7354743       3.9531336\n",
      "[742/1000] loss: 1.7349427       3.6893751\n",
      "[743/1000] loss: 1.724961       3.7334199\n",
      "[744/1000] loss: 1.722735       3.6524967\n",
      "[745/1000] loss: 1.7207165       3.7052475\n",
      "[746/1000] loss: 1.7240202       3.6756111\n",
      "[747/1000] loss: 1.7206561       3.6573335\n",
      "[748/1000] loss: 1.7162747       3.7009074\n",
      "[749/1000] loss: 1.7260043       3.655973\n",
      "[750/1000] loss: 1.7320731       3.6596247\n",
      "[751/1000] loss: 1.7102764       3.687865\n",
      "[752/1000] loss: 1.7233972       4.0750976\n",
      "[753/1000] loss: 1.7122855       3.7094503\n",
      "[754/1000] loss: 1.7213108       3.7980283\n",
      "[755/1000] loss: 1.7250158       3.6428113\n",
      "[756/1000] loss: 1.7156263       3.6613191\n",
      "[757/1000] loss: 1.7102277       3.67435\n",
      "[758/1000] loss: 1.7101367       3.867585\n",
      "[759/1000] loss: 1.7120028       3.6398792\n",
      "[760/1000] loss: 1.7117925       3.6476228\n",
      "[761/1000] loss: 1.7128077       3.6291553\n",
      "[762/1000] loss: 1.7121582       3.8417444\n",
      "[763/1000] loss: 1.7078206       3.7562675\n",
      "[764/1000] loss: 1.7039513       3.671641\n",
      "[765/1000] loss: 1.709657       3.6857807\n",
      "[766/1000] loss: 1.7163064       4.2934071\n",
      "[767/1000] loss: 1.7042639       3.7428006\n",
      "[768/1000] loss: 1.7120329       3.6505942\n",
      "[769/1000] loss: 1.7074775       4.5314681\n",
      "[770/1000] loss: 1.7250168       4.0667612\n",
      "[771/1000] loss: 1.7020562       3.812067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[772/1000] loss: 1.7093382       3.6368157\n",
      "[773/1000] loss: 1.6980958       3.7392171\n",
      "[774/1000] loss: 1.7018216       3.6430777\n",
      "[775/1000] loss: 1.7083944       4.5147977\n",
      "[776/1000] loss: 1.696232       4.5232166\n",
      "[777/1000] loss: 1.7043466       4.0647368\n",
      "[778/1000] loss: 1.7118029       3.5963808\n",
      "[779/1000] loss: 1.6962261       3.7319357\n",
      "[780/1000] loss: 1.6987367       4.5607776\n",
      "[781/1000] loss: 1.6959512       3.6068077\n",
      "[782/1000] loss: 1.6959204       3.7204648\n",
      "[783/1000] loss: 1.6900668       3.7618186\n",
      "[784/1000] loss: 1.6921925       3.6053941\n",
      "[785/1000] loss: 1.6922716       3.7863453\n",
      "[786/1000] loss: 1.6966253       3.6479717\n",
      "[787/1000] loss: 1.6920838       3.6186504\n",
      "[788/1000] loss: 1.6919455       3.6591345\n",
      "[789/1000] loss: 1.6909543       3.7404797\n",
      "[790/1000] loss: 1.7015089       3.57733\n",
      "[791/1000] loss: 1.6883893       3.6355292\n",
      "[792/1000] loss: 1.6853928       3.8009641\n",
      "[793/1000] loss: 1.6861494       3.5935337\n",
      "[794/1000] loss: 1.6876475       3.6586949\n",
      "[795/1000] loss: 1.6836552       3.63736\n",
      "[796/1000] loss: 1.6841241       3.6065463\n",
      "[797/1000] loss: 1.6802798       3.6279774\n",
      "[798/1000] loss: 1.6838159       3.6272625\n",
      "[799/1000] loss: 1.6941193       3.761258\n",
      "[800/1000] loss: 1.6803915       3.6536976\n",
      "[801/1000] loss: 1.6853854       3.5905545\n",
      "[802/1000] loss: 1.6818756       3.5862473\n",
      "[803/1000] loss: 1.677678       3.6067993\n",
      "[804/1000] loss: 1.6793123       3.6764532\n",
      "[805/1000] loss: 1.6752029       3.9617108\n",
      "[806/1000] loss: 1.6858885       3.5633331\n",
      "[807/1000] loss: 1.6849608       3.6894189\n",
      "[808/1000] loss: 1.6788611       3.6142758\n",
      "[809/1000] loss: 1.6737328       3.6868237\n",
      "[810/1000] loss: 1.6862081       3.6493298\n",
      "[811/1000] loss: 1.6871015       3.7046588\n",
      "[812/1000] loss: 1.6701222       3.6598642\n",
      "[813/1000] loss: 1.6725221       3.7699931\n",
      "[814/1000] loss: 1.6820084       3.8737552\n",
      "[815/1000] loss: 1.6685437       3.5716106\n",
      "[816/1000] loss: 1.6727911       3.5490495\n",
      "[817/1000] loss: 1.6687403       3.5827986\n",
      "[818/1000] loss: 1.6781197       3.5438678\n",
      "[819/1000] loss: 1.6871644       3.6577687\n",
      "[820/1000] loss: 1.674647       3.6930669\n",
      "[821/1000] loss: 1.6698375       3.9211469\n",
      "[822/1000] loss: 1.6686287       3.6801131\n",
      "[823/1000] loss: 1.6813809       3.5705161\n",
      "[824/1000] loss: 1.6759579       3.7918166\n",
      "[825/1000] loss: 1.667555       3.5729747\n",
      "[826/1000] loss: 1.6643749       3.5669176\n",
      "[827/1000] loss: 1.6629981       3.8136527\n",
      "[828/1000] loss: 1.6664229       3.5710868\n",
      "[829/1000] loss: 1.6604688       3.5611532\n",
      "[830/1000] loss: 1.6613949       3.6538485\n",
      "[831/1000] loss: 1.6621079       3.6154299\n",
      "[832/1000] loss: 1.6808029       3.6223577\n",
      "[833/1000] loss: 1.6803908       3.552629\n",
      "[834/1000] loss: 1.6625613       3.7851144\n",
      "[835/1000] loss: 1.6794998       3.5906352\n",
      "[836/1000] loss: 1.6587797       3.5611221\n",
      "[837/1000] loss: 1.6600379       4.6252031\n",
      "[838/1000] loss: 1.6657726       3.7680336\n",
      "[839/1000] loss: 1.6548773       3.5304625\n",
      "[840/1000] loss: 1.6634291       3.5703318\n",
      "[841/1000] loss: 1.6548322       4.5723945\n",
      "[842/1000] loss: 1.6820716       4.229796\n",
      "[843/1000] loss: 1.6669598       4.5498708\n",
      "[844/1000] loss: 1.6618241       3.8272857\n",
      "[845/1000] loss: 1.6552496       4.7521745\n",
      "[846/1000] loss: 1.6611471       3.5554951\n",
      "[847/1000] loss: 1.6620919       4.0346939\n",
      "[848/1000] loss: 1.6551146       3.628834\n",
      "[849/1000] loss: 1.6507507       4.4232272\n",
      "[850/1000] loss: 1.6505706       3.5066285\n",
      "[851/1000] loss: 1.6589092       3.6536869\n",
      "[852/1000] loss: 1.6499604       3.5470896\n",
      "[853/1000] loss: 1.6529138       3.7079284\n",
      "[854/1000] loss: 1.6500337       3.550646\n",
      "[855/1000] loss: 1.6556222       4.3934004\n",
      "[856/1000] loss: 1.6501006       3.4812611\n",
      "[857/1000] loss: 1.6466007       3.755039\n",
      "[858/1000] loss: 1.6437457       3.7641044\n",
      "[859/1000] loss: 1.6464904       3.6884083\n",
      "[860/1000] loss: 1.6436993       3.4807135\n",
      "[861/1000] loss: 1.6592522       4.3908127\n",
      "[862/1000] loss: 1.6445915       3.7806688\n",
      "[863/1000] loss: 1.649941       3.4626056\n",
      "[864/1000] loss: 1.6448282       3.5019983\n",
      "[865/1000] loss: 1.6455335       3.5516605\n",
      "[866/1000] loss: 1.6416629       3.5144519\n",
      "[867/1000] loss: 1.6520731       3.5103173\n",
      "[868/1000] loss: 1.6445997       3.5809995\n",
      "[869/1000] loss: 1.641427       3.5155294\n",
      "[870/1000] loss: 1.6416117       3.4838111\n",
      "[871/1000] loss: 1.6572677       3.5619144\n",
      "[872/1000] loss: 1.6447213       3.6543618\n",
      "[873/1000] loss: 1.6393229       3.4780411\n",
      "[874/1000] loss: 1.6558514       3.4952543\n",
      "[875/1000] loss: 1.6382929       3.5172646\n",
      "[876/1000] loss: 1.639903       3.8765906\n",
      "[877/1000] loss: 1.6500377       3.4628075\n",
      "[878/1000] loss: 1.6338376       3.4695425\n",
      "[879/1000] loss: 1.6376291       3.4919072\n",
      "[880/1000] loss: 1.6383665       3.5183153\n",
      "[881/1000] loss: 1.6379831       3.6528407\n",
      "[882/1000] loss: 1.631612       3.710384\n",
      "[883/1000] loss: 1.63438       3.546054\n",
      "[884/1000] loss: 1.6307279       3.9025612\n",
      "[885/1000] loss: 1.6453332       3.465145\n",
      "[886/1000] loss: 1.6354621       3.4843176\n",
      "[887/1000] loss: 1.6280386       4.5477363\n",
      "[888/1000] loss: 1.6553704       3.5239528\n",
      "[889/1000] loss: 1.6338054       4.3127055\n",
      "[890/1000] loss: 1.6316905       3.4517141\n",
      "[891/1000] loss: 1.6321111       3.5659985\n",
      "[892/1000] loss: 1.631115       3.4934852\n",
      "[893/1000] loss: 1.6293828       3.4579305\n",
      "[894/1000] loss: 1.6285773       3.518174\n",
      "[895/1000] loss: 1.6353678       3.4771658\n",
      "[896/1000] loss: 1.6423075       3.4360769\n",
      "[897/1000] loss: 1.6411456       3.4452129\n",
      "[898/1000] loss: 1.6276295       3.6036918\n",
      "[899/1000] loss: 1.6355842       3.464549\n",
      "[900/1000] loss: 1.6301858       3.5173169\n",
      "[901/1000] loss: 1.6222521       3.5934402\n",
      "[902/1000] loss: 1.6250966       3.4451226\n",
      "[903/1000] loss: 1.6354137       3.4894447\n",
      "[904/1000] loss: 1.637612       3.5627085\n",
      "[905/1000] loss: 1.6250608       3.4311862\n",
      "[906/1000] loss: 1.6348905       3.5989717\n",
      "[907/1000] loss: 1.624608       3.5045847\n",
      "[908/1000] loss: 1.6383768       3.4404993\n",
      "[909/1000] loss: 1.6305331       3.4254265\n",
      "[910/1000] loss: 1.6333112       3.5710317\n",
      "[911/1000] loss: 1.6254768       3.4515322\n",
      "[912/1000] loss: 1.624464       3.4359502\n",
      "[913/1000] loss: 1.6188749       3.5800973\n",
      "[914/1000] loss: 1.6199375       3.6401486\n",
      "[915/1000] loss: 1.6184709       3.5202448\n",
      "[916/1000] loss: 1.6240079       3.4081077\n",
      "[917/1000] loss: 1.6269587       3.4358372\n",
      "[918/1000] loss: 1.6188917       3.4449853\n",
      "[919/1000] loss: 1.6259382       3.5652494\n",
      "[920/1000] loss: 1.615085       3.3947667\n",
      "[921/1000] loss: 1.6156193       3.402349\n",
      "[922/1000] loss: 1.6150724       3.6214549\n",
      "[923/1000] loss: 1.6222072       3.7834022\n",
      "[924/1000] loss: 1.6159667       3.392819\n",
      "[925/1000] loss: 1.6131793       3.4880864\n",
      "[926/1000] loss: 1.6127691       3.5245901\n",
      "[927/1000] loss: 1.6126894       3.4772214\n",
      "[928/1000] loss: 1.6165455       3.3979039\n",
      "[929/1000] loss: 1.6195304       3.5904088\n",
      "[930/1000] loss: 1.6140053       3.4530993\n",
      "[931/1000] loss: 1.6074522       3.5530854\n",
      "[932/1000] loss: 1.6120228       3.5698724\n",
      "[933/1000] loss: 1.6115448       3.3919193\n",
      "[934/1000] loss: 1.6069541       3.5551448\n",
      "[935/1000] loss: 1.6081783       3.5111611\n",
      "[936/1000] loss: 1.6130126       3.8512226\n",
      "[937/1000] loss: 1.6088516       3.693733\n",
      "[938/1000] loss: 1.6048694       3.43597\n",
      "[939/1000] loss: 1.6059321       3.3961845\n",
      "[940/1000] loss: 1.6061865       3.4220276\n",
      "[941/1000] loss: 1.6077095       3.6794625\n",
      "[942/1000] loss: 1.6047109       3.5036238\n",
      "[943/1000] loss: 1.607908       3.3942724\n",
      "[944/1000] loss: 1.604002       3.5327124\n",
      "[945/1000] loss: 1.6011956       3.3736826\n",
      "[946/1000] loss: 1.5972894       3.4860024\n",
      "[947/1000] loss: 1.6031002       4.2514857\n",
      "[948/1000] loss: 1.6000007       3.8207903\n",
      "[949/1000] loss: 1.6000887       3.4350083\n",
      "[950/1000] loss: 1.5955411       4.2585713\n",
      "[951/1000] loss: 1.6090056       3.3638283\n",
      "[952/1000] loss: 1.6002565       3.7089641\n",
      "[953/1000] loss: 1.5942364       3.5716525\n",
      "[954/1000] loss: 1.5956452       3.5350416\n",
      "[955/1000] loss: 1.6016529       3.3711195\n",
      "[956/1000] loss: 1.5951521       3.3856019\n",
      "[957/1000] loss: 1.5937966       3.367864\n",
      "[958/1000] loss: 1.6179571       3.4039557\n",
      "[959/1000] loss: 1.5947075       3.8353791\n",
      "[960/1000] loss: 1.5966413       3.6177183\n",
      "[961/1000] loss: 1.5983579       3.7708468\n",
      "[962/1000] loss: 1.5903193       3.4260913\n",
      "[963/1000] loss: 1.5938048       3.4078684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964/1000] loss: 1.5895089       3.5433431\n",
      "[965/1000] loss: 1.5964204       3.5256414\n",
      "[966/1000] loss: 1.6052993       3.3807446\n",
      "[967/1000] loss: 1.5995809       3.4080767\n",
      "[968/1000] loss: 1.5907196       3.5161226\n",
      "[969/1000] loss: 1.5902881       3.3987753\n",
      "[970/1000] loss: 1.5846556       3.3855655\n",
      "[971/1000] loss: 1.5934847       3.7432791\n",
      "[972/1000] loss: 1.5885516       3.3784755\n",
      "[973/1000] loss: 1.5953749       3.333149\n",
      "[974/1000] loss: 1.5888943       3.339408\n",
      "[975/1000] loss: 1.5848072       3.3992096\n",
      "[976/1000] loss: 1.582015       4.1923646\n",
      "[977/1000] loss: 1.5858857       3.352651\n",
      "[978/1000] loss: 1.6003589       3.4428353\n",
      "[979/1000] loss: 1.5853155       3.3837726\n",
      "[980/1000] loss: 1.5833794       4.2931161\n",
      "[981/1000] loss: 1.585331       3.3792977\n",
      "[982/1000] loss: 1.5934808       3.3281297\n",
      "[983/1000] loss: 1.5798179       3.3926437\n",
      "[984/1000] loss: 1.577785       3.3168157\n",
      "[985/1000] loss: 1.5800646       3.4005909\n",
      "[986/1000] loss: 1.5816658       4.2016734\n",
      "[987/1000] loss: 1.5799453       3.4215308\n",
      "[988/1000] loss: 1.5802196       4.1812685\n",
      "[989/1000] loss: 1.5861962       3.3691472\n",
      "[990/1000] loss: 1.5943965       3.4375543\n",
      "[991/1000] loss: 1.5856965       3.3711054\n",
      "[992/1000] loss: 1.5746205       3.6197002\n",
      "[993/1000] loss: 1.5795832       4.379625\n",
      "[994/1000] loss: 1.5731708       3.5733669\n",
      "[995/1000] loss: 1.5732635       3.4961211\n",
      "[996/1000] loss: 1.5769202       4.1821004\n",
      "[997/1000] loss: 1.5712392       3.4164298\n",
      "[998/1000] loss: 1.5797919       3.5876012\n",
      "[999/1000] loss: 1.5805329       3.3154867\n",
      "[1000/1000] loss: 1.5742003       3.5113671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f7d6909708>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi/ElEQVR4nO3dfZRddX3v8ff3PJ95ykwmIQ5JMKGGp8SQxCmGogiNLQ9WoYoaV23Bi80qtVf03q4K7R/oH6zLvcvFpd670EUVS28RmhVFsFVbRbjqraKJQMwDNMEAGfI0SUgymafz9L1/7J3JSTJ5mjMze7L357XWrHPO7+yH729P8tm/2Wefvc3dERGRZEhFXYCIiEwehb6ISIIo9EVEEkShLyKSIAp9EZEEyURdwOnMmDHD582bF3UZIiLnlHXr1u1195nHt5829M3sYeAPgD3uvihsmw78EzAPeBX4iLu/Gb53N3A7UAU+7e7/Gra/A/h7oAh8F7jTz+B80Xnz5rF27drT91BEREaY2WujtZ/J4Z2/B64/ru0u4Gl3XwA8Hb7GzC4DVgILw3keNLN0OM+XgVXAgvDn+GWKiMgEO23ou/uPgf3HNd8EPBI+fwS4ua79cXcfdvdtwFbgCjPrAtrc/Wfh6P4f6uYREZFJMtYPcme5+06A8PG8sH02sL1uup6wbXb4/Ph2ERGZROP9Qa6N0uanaB99IWarCA4FccEFF4xPZSISuXK5TE9PD0NDQ1GXEhuFQoE5c+aQzWbPaPqxhv5uM+ty953hoZs9YXsPMLduujnAjrB9zijto3L3h4CHALq7u3VxIJGY6OnpobW1lXnz5mE22lhQzoa7s2/fPnp6epg/f/4ZzTPWwztPAbeGz28FnqxrX2lmeTObT/CB7S/CQ0B9Zrbcgt/0n9TNIyIJMTQ0RGdnpwJ/nJgZnZ2dZ/WX05mcsvkYcA0ww8x6gHuA+4DVZnY78DrwYQB332hmq4FNQAX4lLtXw0XdwdFTNr8X/ohIwijwx9fZbs/Thr67f+wkb604yfT3AveO0r4WWHRW1TXg7//fNjpb8rz/8vMna5UiIlNebC/D8J2fb+RHz2+JugwRmUIOHDjAgw8+eNbz3XjjjRw4cGD8C4pAbEP/gYHP8bE9X4y6DBGZQk4W+tVqdZSpj/rud79Le3v7BFU1uab8tXfGqmpZqFaiLkNEppC77rqLV155hSVLlpDNZmlpaaGrq4sXXniBTZs2cfPNN7N9+3aGhoa48847WbVqFXD0cjCHDx/mhhtu4F3vehf//u//zuzZs3nyyScpFosR9+zMxTb0a5Yh5eWoyxCRk/jCdzayacehcV3mZee3cc/7F570/fvuu48NGzbwwgsv8Oyzz/K+972PDRs2jJzu+PDDDzN9+nQGBwf57d/+bT70oQ/R2dl5zDK2bNnCY489xt/93d/xkY98hG9+85t8/OMfH9d+TKTYhr6nMlhVoS8iJ3fFFVccc377l770JZ544gkAtm/fzpYtW04I/fnz57NkyRIA3vGOd/Dqq69OVrnjIsahnyNdVuiLTFWnGpFPlubm5pHnzz77LD/84Q/52c9+RlNTE9dcc82o57/n8/mR5+l0msHBwUmpdbzE9oNcT2VIuY7pi8hRra2t9PX1jfrewYMH6ejooKmpiZdeeomf//znk1zd5IjvSD+dVeiLyDE6Ozu56qqrWLRoEcVikVmzZo28d/311/OVr3yFxYsXc/HFF7N8+fIIK504sQ19UlnSCn0ROc43vvGNUdvz+Tzf+97oFwo4ctx+xowZbNiwYaT9L//yL8e9vokW28M7R0L/DG7OJSKSGPEN/UyWLBWGK7WoKxERmTJiG/qWzpK1KkPlU3/TTkQkSWIc+jkyVBkqa6QvInJEjEM/OLyjkb6IyFGxDf1UJkeWKkMVhb6IyBHxDf1sLhzp6/COiIxNS0sLADt27OCWW24ZdZprrrmGtWvXnnI5DzzwAAMDAyOvo7xUc2xDP53JkaPMUEnn6otIY84//3zWrFkz5vmPD/0oL9Uc29C3XDNpc4aHz/zekSISb5/73OeOuZ7+5z//eb7whS+wYsUKli1bxtvf/naefPLE23e/+uqrLFoU3PhvcHCQlStXsnjxYj760Y8ec+2dO+64g+7ubhYuXMg999wDBBdx27FjB9deey3XXnstEFyqee/evQDcf//9LFq0iEWLFvHAAw+MrO/SSy/lT//0T1m4cCG///u/P27X+IntN3LTueD61uXhc+tiSCKJ8b27YNevx3eZb3k73HDfSd9euXIln/nMZ/jzP/9zAFavXs33v/99PvvZz9LW1sbevXtZvnw5H/jAB05679kvf/nLNDU1sX79etavX8+yZctG3rv33nuZPn061WqVFStWsH79ej796U9z//3388wzzzBjxoxjlrVu3Tq+/vWv89xzz+HuvPOd7+Q973kPHR0dE3YJ59iO9NP5IPQrw/0RVyIiU8XSpUvZs2cPO3bs4MUXX6Sjo4Ouri7++q//msWLF/Pe976XN954g927d590GT/+8Y9Hwnfx4sUsXrx45L3Vq1ezbNkyli5dysaNG9m0adMp6/npT3/KH/7hH9Lc3ExLSwsf/OAH+clPfgJM3CWcYzvSz+SaACgPDZxmShGJxClG5BPplltuYc2aNezatYuVK1fy6KOP0tvby7p168hms8ybN2/USyrXG+2vgG3btvHFL36RX/7yl3R0dHDbbbeddjmnukzMRF3CObYj/Uw+CP2qRvoiUmflypU8/vjjrFmzhltuuYWDBw9y3nnnkc1meeaZZ3jttddOOf/VV1/No48+CsCGDRtYv349AIcOHaK5uZlp06axe/fuYy7edrJLOl999dV8+9vfZmBggP7+fp544gne/e53j2NvTxTbkX62EIZ+SR/kishRCxcupK+vj9mzZ9PV1cUf/dEf8f73v5/u7m6WLFnCJZdccsr577jjDj7xiU+wePFilixZwhVXXAHA5ZdfztKlS1m4cCEXXnghV1111cg8q1at4oYbbqCrq4tnnnlmpH3ZsmXcdtttI8v45Cc/ydKlSyf0blw21a9C2d3d7ac7B3Y01a3PkP7Hm1n99of4yIc+OgGVicjZ2rx5M5deemnUZcTOaNvVzNa5e/fx08b28E46PKbvJZ29IyJyRGxDn0IbAKnhgxEXIiIydcQ39IsdAGTKCn2RqWSqH1I+15zt9oxv6BfaAciVFPoiU0WhUGDfvn0K/nHi7uzbt49CoXDG88T27B2yBYbIkSsfiroSEQnNmTOHnp4eent7oy4lNgqFAnPmzDnj6eMb+sCgNZGp6Dx9kakim80yf/78qMtItPge3gGqloFaOeoyRESmjJiHfharKvRFRI5oKPTN7LNmttHMNpjZY2ZWMLPpZvYDM9sSPnbUTX+3mW01s5fN7LrGyz+1WiqLaaQvIjJizKFvZrOBTwPd7r4ISAMrgbuAp919AfB0+Bozuyx8fyFwPfCgmaUbK//UqpYhpdAXERnR6OGdDFA0swzQBOwAbgIeCd9/BLg5fH4T8Li7D7v7NmArcEWD6z8lT+UU+iIidcYc+u7+BvBF4HVgJ3DQ3f8NmOXuO8NpdgLnhbPMBrbXLaInbDuBma0ys7VmtraRU7s8nSXlCn0RkSMaObzTQTB6nw+cDzSb2alu6zLabWhG/YaGuz/k7t3u3j1z5syxloinsqQ10hcRGdHI4Z33Atvcvdfdy8C3gN8BdptZF0D4uCecvgeYWzf/HILDQRMnnSNDhXK1NqGrERE5VzQS+q8Dy82syYLbyKwANgNPAbeG09wKHLnL8FPASjPLm9l8YAHwiwbWf1qWyZGlwkCpOpGrERE5Z4z5G7nu/pyZrQF+BVSA54GHgBZgtZndTrBj+HA4/UYzWw1sCqf/lLtPaBpbOkeWKgOlCtOK2YlclYjIOaGhyzC4+z3APcc1DxOM+keb/l7g3kbWeTY00hcROVasv5GbyuTIUWFgWKEvIgIxD33LN9NsgwyUKlGXIiIyJcQ69Cl2MI1+Bko6bVNEBGIe+qmmDtLmlA7rRioiIhDz0M+0zACg2r8v4kpERKaGWId+trkdgNrggUjrEBGZKmId+vlCMwDloYGIKxERmRpiHfq5YhD61ZJCX0QEYh76li0CUC0NRlyJiMjUEOvQJ6PQFxGpF+/QzxaCRx3eEREB4h764Ui/VhmKuBARkakh3qEfjvStrMM7IiIQ+9BvCh4rCn0REYh76KezHEq3M728O+pKRESmhHiHPrAn91ZmV7affkIRkQSIfegP5jpoqfVFXYaIyJQQ+9CvZZoouM7eERGBBIS+Z4oUGKJW86hLERGJXOxDn1wTTQwzVNEtE0VEYh/6lmumYGUGhkpRlyIiErnYhz654Fz9wf7DERciIhK92Id+Ot8CwNDgoYgrERGJXgJCP7j+zvCgLromIhL70M9m8wAMD+m0TRGR2Id+7shIX7dMFBGJf+hn88GVNkvDGumLiMQ+9HOFYKRfVuiLiMQ/9PPh4Z1SSaEvIhL70C+EI/2KQl9EJP6hn8kFx/QrpeGIKxERiV7sQ590cMpmVbdMFBFpLPTNrN3M1pjZS2a22cyuNLPpZvYDM9sSPnbUTX+3mW01s5fN7LrGyz8DmRwA1bJG+iIijY70/xb4vrtfAlwObAbuAp529wXA0+FrzOwyYCWwELgeeNDM0g2u//TCkX5NoS8iMvbQN7M24GrgawDuXnL3A8BNwCPhZI8AN4fPbwIed/dhd98GbAWuGOv6z1ihDYBs6cCEr0pEZKprZKR/IdALfN3Mnjezr5pZMzDL3XcChI/nhdPPBupvVtsTtp3AzFaZ2VozW9vb29tAiUC+lcPWwrThXY0tR0QkBhoJ/QywDPiyuy8F+gkP5ZyEjdI26u2s3P0hd+929+6ZM2c2UGLgzews2su7G16OiMi5rpHQ7wF63P258PUagp3AbjPrAggf99RNP7du/jnAjgbWf8ZK6WayNZ2nLyIy5tB3913AdjO7OGxaAWwCngJuDdtuBZ4Mnz8FrDSzvJnNBxYAvxjr+s+q1kyeTE0f5IqIZBqc/z8Dj5pZDvgN8AmCHclqM7sdeB34MIC7bzSz1QQ7hgrwKXeflBvXeqZA1ku4O2ajHWUSEUmGhkLf3V8Aukd5a8VJpr8XuLeRdY5JpkjOSwxXahSyE3+WqIjIVBX/b+QCli2QtzKHhytRlyIiEqlEhH4qW6RAicNDCn0RSbZEhH46VwhCXyN9EUm4hIR+E3nK9GmkLyIJl4jQzxSKZK3KwKCutCkiyZaM0C8G198Z6j8YcSUiItFKROjnmtsBKPUfiLQOEZGoJSL082HolwcORVuIiEjEEhH6R0b6XbufjbQOEZGoJSL0LRPcJ/fd278ScSUiItFKROhz/lIAXi9cEnEhIiLRavSCa+eGbIGX0wsoW2vUlYiIRCoZI32gksqTquryyiKSbIkJ/Wq6QEY3UhGRhEtM6NcyRd1IRUQSLzGh7+kCWYW+iCRcYkKfbIGcK/RFJNkSFPpNNDNItVqLuhIRkcgkJvQHW+fRYkMM7O+JuhQRkcgkJvRL0y4EYHjPKxFXIiISncSEfrbYDMDQ4EDElYiIRCcxoV8oFAGFvogkW3JCv9gEwPCw7p4lIsmVuNAvDelbuSKSXIkJ/aZicHinUtJIX0SSKzGh3xx+kFvW4R0RSbDEhH5TcxD6lZIO74hIciUm9DO54O5ZCn0RSbLEhD7pPADVsq6/IyLJlZzQT6WokKaqD3JFJMGSE/rAkBVJlQ9HXYaISGQSFfqH023kywejLkNEJDINh76Zpc3seTP75/D1dDP7gZltCR876qa928y2mtnLZnZdo+s+W4OZdporCn0RSa7xGOnfCWyue30X8LS7LwCeDl9jZpcBK4GFwPXAg2aWHof1n7HhXDstNYW+iCRXQ6FvZnOA9wFfrWu+CXgkfP4IcHNd++PuPuzu24CtwBWNrP9slfMdTPNDuPtkrlZEZMpodKT/APBXQP3tqGa5+06A8PG8sH02sL1uup6w7QRmtsrM1prZ2t7e3gZLPKpamE4HfQyWKuO2TBGRc8mYQ9/M/gDY4+7rznSWUdpGHXK7+0Pu3u3u3TNnzhxriScut9hJwcr09R0at2WKiJxLMg3MexXwATO7ESgAbWb2j8BuM+ty951m1gXsCafvAebWzT8H2NHA+s+aNXcCMPDmbpjROZmrFhGZEsY80nf3u919jrvPI/iA9kfu/nHgKeDWcLJbgSfD508BK80sb2bzgQXAL8Zc+RhkW6YDMHh4/2SuVkRkymhkpH8y9wGrzex24HXgwwDuvtHMVgObgArwKXevTsD6TyrfNA2AoT6dwSMiyTQuoe/uzwLPhs/3AStOMt29wL3jsc6xKLQEoV8aUOiLSDIl6hu5xdZ2AMoKfRFJqESFfnNr8OXgymBfxJWIiEQjUaFfaAlC3wb1Qa6IJFOiQp98C7uYQfvhrVFXIiISiWSFPtCTnk3b0BtRlyEiEonEhX453Uy2OhB1GSIikUhc6FcyTeQV+iKSUIkL/Vq2mbzrlokikkyJC33PtVBU6ItIQiUu9C3fTI4KVEpRlyIiMukSF/qpfCsAQwO6vLKIJE/iQj9TDEL/cN+BaAsREYlAYkN/QFfaFJEESlzo54ptAAweVuiLSPIkLvQLzUHo65i+iCRR4kK/2BxcU3+4X6EvIsmTuNBvbmsHdE19EUmmxIV+64zZwZO+XdEWIiISgcSFfq6pjYPeTLZ/Z9SliIhMusSFPsC+VCf5wT1RlyEiMukSGfpD6RYy5cNRlyEiMukSGfqVTDPZSn/UZYiITLpEhn4110q+ptAXkeRJZOiTa6FY041URCR5Ehn6VmilhQGGSpWoSxERmVSJDP1S23yabJi+HS9HXYqIyKRKZOhX37IYgMGdL0VciYjI5Epk6De3BBddGxjQaZsikiyJDP3W1vDyyv0KfRFJlkSGfltbcCOV4UGdtikiyZLI0J/WEoR+SaEvIgkz5tA3s7lm9oyZbTazjWZ2Z9g+3cx+YGZbwseOunnuNrOtZvaymV03Hh0Yi0yhBYDysEJfRJKlkZF+Bfiv7n4psBz4lJldBtwFPO3uC4Cnw9eE760EFgLXAw+aWbqR4scsnaVKivKQQl9EkmXMoe/uO939V+HzPmAzMBu4CXgknOwR4Obw+U3A4+4+7O7bgK3AFWNdf6OGrUB5WN/KFZFkGZdj+mY2D1gKPAfMcvedEOwYgPPCyWYD2+tm6wnbRlveKjNba2Zre3t7x6PEE5TTRWy4b0KWLSIyVTUc+mbWAnwT+Iy7n+rGszZKm482obs/5O7d7t49c+bMRksc1UBuBq3lfbiPWoKISCw1FPpmliUI/Efd/Vth824z6wrf7wKO3K2kB5hbN/scYEcj629EuWkWM3mTQ4O6/o6IJEcjZ+8Y8DVgs7vfX/fWU8Ct4fNbgSfr2leaWd7M5gMLgF+Mdf2Nqkx7K/NtJ3v274uqBBGRSdfISP8q4I+B3zWzF8KfG4H7gN8zsy3A74WvcfeNwGpgE/B94FPuXm2o+gaUL7iaopXof/3FqEoQEZl0mbHO6O4/ZfTj9AArTjLPvcC9Y13neGrrfAsA/Qc00heR5EjkN3IB2juDk4oG+vZGXImIyORJbOgX22YAUO7bH3ElIiKTJ7GhT6E9eByYmO8BiIhMRckN/XSGNzJzOe/wf0RdiYjIpElu6AO9xd9iZrkn6jJERCZNokO/1jKLjtoBytVa1KWIiEyKRId+tm0WbTbA7n1vRl2KiMikSHToFzvOB2D3zu2nmVJEJB4SHfptM4KLfL65542IKxERmRyJDv2OWXMA6N8X2XXfREQmVaJDPzstuBRD7YAO74hIMiQ69GntYle6izlvPhd1JSIikyLZoW9Gb8tFdA7rXH0RSYZkhz7AtLl0+R7ePDwcdSUiIhMu8aGfnzGfopV4bfurUZciIjLhEh/6Hee/DYDe7VsirkREZOIlPvSnz70EgPKOX0dciYjIxEt86KfPu5g9qZlM3/2zqEsREZlwiQ99zDhUnEthcCfuHnU1IiITSqEPpNrnsIT/4PU9uouWiMSbQh/Iz78SgD3rvhNxJSIiE0uhD8z8nT8GYOCNDRFXIiIysRT6QK6plZ2pt5DZp1sniki8KfRDh1rfRtfgFgZL1ahLERGZMAr9UObCd3Oh7eDFX78QdSkiIhNGoR+ac+UtABx8/omIKxERmTgK/VD+vLfxam4BF7zxPWo1na8vIvGk0K/Td9EHudS3sn7dT6IuRURkQij06yy47s/o9wKln/yvqEsREZkQCv06hdbpbHzLTSw9+DSvb/p51OWIiIw7hf5xLrr5bvpoomPNh6ke1A3TRSReFPrHae+az4tX/i1N1T7S//NSauvXQK0GuhibiMRAZrJXaGbXA38LpIGvuvt9k13D6Vx7/Yf4pwOHuXrz5+n61u3wrduDNy7/GFywHJpmQL4FtvwASoeh+z/Brg2w/zdw2Qdg53rouhwOvAbtF8Drz8HcK6C1C7LFYJ7KMDR1wtABSGUg3wr7tkI6DzMuglQa+nbB4Jsw8+Jgp9PfC+UBeOlfYPFHoTAtaCu2Q/9eyDZB66yjHSn1w/DhYPnNnUHb0MFguv690DILUqlgp7ZvS7Bes2BdZsH01Qps+78w792QyZ24seqnrVWDums1wIPnIjKl2GReTtjM0sB/AL8H9AC/BD7m7ptONk93d7evXbt2kio81nde2M7af3mYPxl+jN9K7Zy09ToGZpjXzmx6S41MW80UqebaACM7uGekvdR8PliK3OFjbwI/3DaPzGAv6XJ/MF3rBaTKfaQqw1QLHWQPvzEybbllNtWmmcFOxIz04H7S/buptM3FahUyB16hVuwkPdAb1NL8FmqFdsxrVFtnj+wE0gdfIzV0gMqMS0j37aA67QLMUlCrYMOH8OJ0rFbG862QbwNLYakUTiqYjhpWLYWd95F9Dqk0ls7Bb56FlvOw5pmQyUOhHfBgp1Tqh1xTsEPtXBDs9FJZSGfh0I6gxlQ22Bm3vxUO7w521oVpR3eIh3YEO9GB/UF9xY5g+oM9wfqmzQl2qtPmQq0MB14P2osdwY+FO8Mdz8P0+VCcDpWhup1k8PtnYD9Uy9DxVrBUUL+H3xjP5KF/HzRNB69BtRRMW6vUPS8HO+1sMdjBey0YrJT6g+nybcF2sXTwXnkgGBQ0z4Rcc9CWygbLS6WD+coDwUCi0BYMUFKpYJsMvhn8u/BqMCiqDAX9slTQlyOPfuSvZgcneA0wuD+YP5UJtlG9kV9wOP3x/y8sHcwXTBD8HrBwu+eCgVetenT56VzQv2op2A7uwcAJgnnKAzDj4rr12tHf/ZH1ey3Yvulc3brtaA2VITi8J/j9ZApB/zmyHVLB+ziUh4Ll5FqCf2vFjmA7F9qCZc9dHmzjMTCzde7efUL7JIf+lcDn3f268PXdAO7+3042T5ShD1CrOb98dT/PbdvP1l37GXpzFzawFxs6wNahVn6LHWSokqVCwUpkqTDHetnl05lpB+n1aSxNbeXl2lwO0kyBEjnKHKZInjJlMjhGjjIXWQ+b/a20Wx9pahzyZpanNrHR5+EYC+wN9nkbfRQpkaGZYdJUKZPhIuuhnwKHvAkI/vnNsINMtz4c2OZdgLPIXuVXtQXs8E66bD+tNkC/F1iRfp4fVpfRbEOkcHp9Gu12mLfbNt6W2sHa2kX0+jSaGCZFjRROiw3SaYfYWJtHhirvSm3gR7UlzLI3mW172e+tDJGnRIYCpZFtmqPMNOvnoDeHSzKyVABosUFqnuIQTbQyQNpqGE4q/DGC//DDHP2rwz34z5axKs0M0maD7PNWKqRpY4ASGVI4rTZ4zO/2sBdIUwt+f6bLb8jUM3zXDvKF5jHNO1VC/xbgenf/ZPj6j4F3uvtfHDfdKmAVwAUXXPCO1157bdJqPBvuTrXmlKo1ypXwMfypefB+/WPNPRgs4CMfEdS/9nCZzpGPELxumvCx7n0PR0tHpz92WdQtj/r1jPL+kfUds65RlnVCzcfVzSh1nLCsI9OO2qfR13Nk0Sduv2PXc8I2OKZ/x/3+qGsMR3HmjpsBTrpWoWoZ3IxsdXCkiEoqS6Y2jJMixZHRd4pKKkvVshTLhyinC+Sq/RhQSuWpWJ58rZ90rRwup0Y5lSdbGwacKhkMD/7KA8xr1CxFzdLkq/3Ba9LULBj1ZWvDVC1LyktULUPVstQsQ4UMNctQTWWpWoYaaaaVd5OtDeGkyNSGKVuWtFfCjtvIXw8ZL1O1TLj+KmCkvErVskCVcqpAtjZExXJkvETNgz5nvELV0phXcdKkvRxsF4BasNM26rdt8NdssBtn5DUYxWofZctyzKi57ndUC0fMR7YT7qSohfWGTRYMD/rS7TRV+yhU+zmYnUmh2keKKimv4qSoWLCtcKdY68cxMl4i7WWGU03BOryGjdRhwe8krL1mKTJeCaep+0dqUMNIuZPxEkOppuAv0nBO8xpuKfK1AQDSXqGUKpCuVRlOFcl4CccopQr82a23kctlT/zHewZOFvqTfUzfRmk74b+juz8EPATBSH+iixorMyOTNjLpFIxyuFtkalgUdQEyhUz22Ts9wNy613MAnRcpIjJJJjv0fwksMLP5ZpYDVgJPTXINIiKJNamHd9y9YmZ/AfwrwSmbD7v7xsmsQUQkySb9PH13/y7w3cler4iI6Bu5IiKJotAXEUkQhb6ISIIo9EVEEmRSv5E7FmbWC4z1K7kzgL3jWM65QH1OBvU5GRrp81vdfebxjVM+9BthZmtH+xpynKnPyaA+J8NE9FmHd0REEkShLyKSIHEP/YeiLiAC6nMyqM/JMO59jvUxfREROVbcR/oiIlJHoS8ikiCxDH0zu97MXjazrWZ2V9T1jBczm2tmz5jZZjPbaGZ3hu3TzewHZrYlfOyom+fucDu8bGbXRVd9Y8wsbWbPm9k/h69j3WczazezNWb2Uvj7vjIBff5s+O96g5k9ZmaFuPXZzB42sz1mtqGu7az7aGbvMLNfh+99ycxGu0HV6ILbzcXnh+CSza8AFxLcz+pF4LKo6xqnvnUBy8LnrQQ3mb8M+B/AXWH7XcB/D59fFvY/D8wPt0s66n6Mse//BfgG8M/h61j3GXgE+GT4PAe0x7nPwGxgG1AMX68Gbotbn4GrgWXAhrq2s+4j8AvgSoK7EX4PuOFMa4jjSP8KYKu7/8bdS8DjwE0R1zQu3H2nu/8qfN4HbCb4z3ITQUgQPt4cPr8JeNzdh919G7CVYPucU8xsDvA+4Kt1zbHts5m1EYTD1wDcveTuB4hxn0MZoGhmGaCJ4K56seqzu/8Y2H9c81n10cy6gDZ3/5kHe4B/qJvntOIY+rOB7XWve8K2WDGzecBS4DlglrvvhGDHAJwXThaXbfEA8FdAra4tzn2+EOgFvh4e0vqqmTUT4z67+xvAF4HXgZ3AQXf/N2Lc5zpn28fZ4fPj289IHEP/jG6+fi4zsxbgm8Bn3P3QqSYdpe2c2hZm9gfAHndfd6azjNJ2TvWZYMS7DPiyuy8F+gn+7D+Zc77P4XHsmwgOY5wPNJvZx081yyht51Sfz8DJ+thQ3+MY+rG++bqZZQkC/1F3/1bYvDv8k4/wcU/YHodtcRXwATN7leBQ3e+a2T8S7z73AD3u/lz4eg3BTiDOfX4vsM3de929DHwL+B3i3ecjzraPPeHz49vPSBxDP7Y3Xw8/of8asNnd76976yng1vD5rcCTde0rzSxvZvOBBQQfAJ0z3P1ud5/j7vMIfpc/cvePE+8+7wK2m9nFYdMKYBMx7jPBYZ3lZtYU/jtfQfCZVZz7fMRZ9TE8BNRnZsvDbfUndfOcXtSfZk/QJ+Q3EpzZ8grwN1HXM479ehfBn3HrgRfCnxuBTuBpYEv4OL1unr8Jt8PLnMUn/FPxB7iGo2fvxLrPwBJgbfi7/jbQkYA+fwF4CdgA/B+Cs1Zi1WfgMYLPLMoEI/bbx9JHoDvcTq8A/5vw6gpn8qPLMIiIJEgcD++IiMhJKPRFRBJEoS8ikiAKfRGRBFHoi4gkiEJfRCRBFPoiIgny/wEtkG05pQ4KhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = df1.columns.tolist()\n",
    "for n in name:\n",
    "    train1[n] = train1[n].astype(float)\n",
    "    va1[n] = va1[n].astype(float)\n",
    "\n",
    "data = mydata(train1)\n",
    "train_loader = DataLoader(dataset=data,batch_size=64,shuffle=True)\n",
    "\n",
    "data = mydata(va1)\n",
    "valid_loader = DataLoader(dataset=data,batch_size=64,shuffle=True)\n",
    "\n",
    "dnn = dnn()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(dnn.parameters(), lr=1e-5)\n",
    "    \n",
    "tl,vl,model = train( dnn, 100, optimizer, loss_function, train_loader, valid_loader)\n",
    "plt.plot(tl,label='train')\n",
    "plt.plot(vl,label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fe89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dnn,self).__init__()\n",
    "        self.hid1 = nn.Linear(17, 17)  \n",
    "        self.hid2 = nn.Linear(17, 17)\n",
    "        #self.hid3 = nn.Linear(8, 8)\n",
    "        #self.hid4 = nn.Linear(8, 17)\n",
    "        self.hid5 = nn.Linear(17, 17)\n",
    "        self.oupt = nn.Linear(17, 1)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = F.relu(self.hid1(x))\n",
    "        z = F.relu(self.hid2(z))\n",
    "        #z = F.relu(self.hid3(z))\n",
    "        #z = F.relu(self.hid4(z))\n",
    "        z = F.relu(self.hid5(z))\n",
    "        z = self.oupt(z)  \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1ce39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
